<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nipun Batra">
<meta name="description" content="A programming introduction to Gaussian Processes.">

<title>blog - Gaussian Processes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Gaussian Processes</h1>
                  <div>
        <div class="description">
          A programming introduction to Gaussian Processes.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">ML</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nipun Batra </p>
            </div>
    </div>
      
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#an-example" id="toc-an-example" class="nav-link active" data-scroll-target="#an-example">An example</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#some-imports" id="toc-some-imports" class="nav-link" data-scroll-target="#some-imports">Some imports</a></li>
  <li><a href="#a-function-to-make-the-matplotlib-plots-prettier" id="toc-a-function-to-make-the-matplotlib-plots-prettier" class="nav-link" data-scroll-target="#a-function-to-make-the-matplotlib-plots-prettier">A function to make the Matplotlib plots prettier</a></li>
  <li><a href="#one-dimensional-gaussiannormal" id="toc-one-dimensional-gaussiannormal" class="nav-link" data-scroll-target="#one-dimensional-gaussiannormal">One dimensional Gaussian/Normal</a></li>
  <li><a href="#bi-variate-gaussian" id="toc-bi-variate-gaussian" class="nav-link" data-scroll-target="#bi-variate-gaussian">Bi-variate Gaussian</a></li>
  <li><a href="#marginalisation-for-bivariate-gaussian" id="toc-marginalisation-for-bivariate-gaussian" class="nav-link" data-scroll-target="#marginalisation-for-bivariate-gaussian">Marginalisation for bivariate Gaussian</a></li>
  <li><a href="#sample-from-2d-gaussian-and-visualising-it-on-xy-plane" id="toc-sample-from-2d-gaussian-and-visualising-it-on-xy-plane" class="nav-link" data-scroll-target="#sample-from-2d-gaussian-and-visualising-it-on-xy-plane">Sample from 2d gaussian and visualising it on XY plane</a></li>
  <li><a href="#conditional-bivariate-distribution" id="toc-conditional-bivariate-distribution" class="nav-link" data-scroll-target="#conditional-bivariate-distribution">Conditional Bivariate Distribution</a></li>
  <li><a href="#conditional-multivariate-distribution" id="toc-conditional-multivariate-distribution" class="nav-link" data-scroll-target="#conditional-multivariate-distribution">Conditional Multivariate Distribution</a></li>
  <li><a href="#lets-increase-to-20-dimensions-now" id="toc-lets-increase-to-20-dimensions-now" class="nav-link" data-scroll-target="#lets-increase-to-20-dimensions-now">Let’s increase to 20 dimensions now!</a></li>
  <li><a href="#kernels" id="toc-kernels" class="nav-link" data-scroll-target="#kernels">Kernels!</a></li>
  <li><a href="#creating-a-scikit-learn-like-function-containing-fit-and-predict" id="toc-creating-a-scikit-learn-like-function-containing-fit-and-predict" class="nav-link" data-scroll-target="#creating-a-scikit-learn-like-function-containing-fit-and-predict">Creating a scikit-learn like function containing <code>fit</code> and <code>predict</code></a></li>
  <li><a href="#cholesky-decomposition" id="toc-cholesky-decomposition" class="nav-link" data-scroll-target="#cholesky-decomposition">Cholesky decomposition</a></li>
  <li><a href="#noisy-gps" id="toc-noisy-gps" class="nav-link" data-scroll-target="#noisy-gps">Noisy GPs</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="an-example" class="level3">
<h3 class="anchored" data-anchor-id="an-example">An example</h3>
<p><img src="20d-conditional-main.gif" class="img-fluid"></p>
<p>Let us look at the GIF above. It shows a non-linear fit with uncertainty on a set of points in the 2d space. The uncertainty is shown by the gray shadowed region. The animation shows how the fit and the uncertainty varies as we keep adding more points (shown as big circles). As expected, as more points are added, the uncertainty of the fit in the vicinity of the added points reduces. This is an example of Gaussian Processes (GP) regression in play.</p>
</section>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>There exist some great online resources for Gaussian Processes (GPs) including an excellent recent <a href="https://www.jgoertler.com/visual-exploration-gaussian-processes/">Distill.Pub article</a>. This blog post is an attempt with a programatic flavour. In this notebook, we will build the intuition and learn some basics of GPs. This notebook is heavily inspired by the awesome tutorial by Richard Turner. Here is the link to the <a href="http://cbl.eng.cam.ac.uk/pub/Public/Turner/News/imperial-gp-tutorial.pdf">slides</a> and <a href="https://www.youtube.com/watch?v=92-98SYOdlY">video</a>. Lectures videos and notes from Nando De Freitas’ <a href="https://www.cs.ubc.ca/~nando/540-2013/lectures.html">course</a> are an amazing resource for GPs (and anything ML!).</p>
</section>
<section id="some-imports" class="level3">
<h3 class="anchored" data-anchor-id="some-imports">Some imports</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="a-function-to-make-the-matplotlib-plots-prettier" class="level3">
<h3 class="anchored" data-anchor-id="a-function-to-make-the-matplotlib-plots-prettier">A function to make the Matplotlib plots prettier</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>SPINE_COLOR <span class="op">=</span> <span class="st">'gray'</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> format_axes(ax):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> spine <span class="kw">in</span> [<span class="st">'top'</span>, <span class="st">'right'</span>]:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        ax.spines[spine].set_visible(<span class="va">False</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> spine <span class="kw">in</span> [<span class="st">'left'</span>, <span class="st">'bottom'</span>]:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        ax.spines[spine].set_color(SPINE_COLOR)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        ax.spines[spine].set_linewidth(<span class="fl">0.5</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_ticks_position(<span class="st">'bottom'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_ticks_position(<span class="st">'left'</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> axis <span class="kw">in</span> [ax.xaxis, ax.yaxis]:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        axis.set_tick_params(direction<span class="op">=</span><span class="st">'out'</span>, color<span class="op">=</span>SPINE_COLOR)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ax</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="one-dimensional-gaussiannormal" class="level3">
<h3 class="anchored" data-anchor-id="one-dimensional-gaussiannormal">One dimensional Gaussian/Normal</h3>
<p>We will start the discussion with 1d Gaussians. Let us write some simple code to generate/sample data from <span class="math inline">\(\mathcal{N}(\mu=0, \sigma=1)\)</span></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>one_dim_normal_data <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span><span class="dv">10000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us now visualise the data in a 1d space using scatter plot</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(one_dim_normal_data, np.zeros_like(one_dim_normal_data), alpha<span class="op">=</span><span class="fl">0.2</span>, c<span class="op">=</span><span class="st">'gray'</span>, edgecolors<span class="op">=</span><span class="st">'k'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d08faed90&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-5-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>As we would expect, there are a lot of samples close to zero (mean) and as we go further away from zero, the number of samples keeps reducing. We can also visualise the same phenomenon using a normed histogram shown below.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>plt.hist(one_dim_normal_data, density<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d090a4a60&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-6-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can notice that there is a high probability of drawing samples close to the mean and the probability is low far from the mean.</p>
<p>However, since histograms come with their own set of <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.13-kernel-density-estimation.html">caveats</a>, let us use kernel desnity estimation for obtaining the probability density of 1d Gaussian.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KernelDensity</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>x_d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">100</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># instantiate and fit the KDE model</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>kde <span class="op">=</span> KernelDensity(bandwidth<span class="op">=</span><span class="fl">1.0</span>, kernel<span class="op">=</span><span class="st">'gaussian'</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>kde.fit(one_dim_normal_data[:, <span class="va">None</span>])</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># score_samples returns the log of the probability density</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>logprob <span class="op">=</span> kde.score_samples(x_d[:, <span class="va">None</span>])</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>plt.fill_between(x_d, np.exp(logprob), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>plt.plot(one_dim_normal_data, np.full_like(one_dim_normal_data, <span class="op">-</span><span class="fl">0.01</span>), <span class="st">'|k'</span>, markeredgewidth<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d0a08c340&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-7-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can now see a smoother version of the histogram and can again verify the properties of 1D Gaussian. Let us now vary the variance of 1D Gaussian and make the same plots to enhance our understanding of the concept.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">3</span>, sharey<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">3</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>x_d <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">400</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, var <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>]):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    one_dim_normal_data <span class="op">=</span> np.random.normal(<span class="dv">0</span>, var, size<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    kde <span class="op">=</span> KernelDensity(bandwidth<span class="op">=</span><span class="fl">1.0</span>, kernel<span class="op">=</span><span class="st">'gaussian'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    kde.fit(one_dim_normal_data[:, <span class="va">None</span>])</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># score_samples returns the log of the probability density</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    logprob <span class="op">=</span> kde.score_samples(x_d[:, <span class="va">None</span>])</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    ax[i].fill_between(x_d, np.exp(logprob), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    ax[i].plot(one_dim_normal_data, np.full_like(one_dim_normal_data, <span class="op">-</span><span class="fl">0.01</span>), <span class="st">'|k'</span>, markeredgewidth<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[i])</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    ax[i].set_title(<span class="ss">f"Variance = </span><span class="sc">{</span>var<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can see that how increasing the variance makes the data more spread.</p>
</section>
<section id="bi-variate-gaussian" class="level3">
<h3 class="anchored" data-anchor-id="bi-variate-gaussian">Bi-variate Gaussian</h3>
<p>Having discussed the case of 1d Gaussian, now let us move to multivariate Gaussians. As a special case, let us first consider bi-variate or 2d Gaussian. It’s parameters are the mean vector which will have 2 elements and a covariance matrix.</p>
<p>We can write the distribution as: <span class="math display">\[
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
\mu_1 \\
\mu_2
\end{pmatrix} , \begin{pmatrix}
a &amp; \rho \\
\rho &amp; b
\end{pmatrix} \right)
\]</span></p>
<p>where <span class="math inline">\(\mu_1\)</span>, <span class="math inline">\(\mu_2\)</span> are the means for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> respectively; <span class="math inline">\(a\)</span> is the standard deviation for <span class="math inline">\(X_1\)</span>, <span class="math inline">\(b\)</span> is the standard deviation for <span class="math inline">\(X_2\)</span> and <span class="math inline">\(\rho\)</span> is the correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span></p>
<p>Let us now draw some data from: <span class="math display">\[
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
0 \\
0
\end{pmatrix} , \begin{pmatrix}
1 &amp; 0.7 \\
0.7 &amp; 1
\end{pmatrix} \right)
\]</span></p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.random.multivariate_normal(mean <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>]), cov <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="fl">0.7</span>], [<span class="fl">0.7</span>, <span class="dv">1</span>]]), size<span class="op">=</span>(<span class="dv">10000</span>, ))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.05</span>,c<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>plt.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, lw<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'k'</span>, lw<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="vs">r"$X_1$"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$X_2$"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d0a235610&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can see from the plot above that the data is distributed around mean [0, 0]. We can also see the positive correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span></p>
</section>
<section id="marginalisation-for-bivariate-gaussian" class="level3">
<h3 class="anchored" data-anchor-id="marginalisation-for-bivariate-gaussian">Marginalisation for bivariate Gaussian</h3>
<p>Let us look into an interesting plot provided by Seaborn.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>data_df <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>[<span class="vs">r'$X_1$'</span>,<span class="vs">r'$X_2$'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.jointplot(x<span class="op">=</span> <span class="vs">r'$X_1$'</span>, y<span class="op">=</span><span class="vs">r'$X_2$'</span>, data<span class="op">=</span>data_df, kind<span class="op">=</span><span class="st">"reg"</span>,color<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The central plot is exactly the same as the scatter plot we made earlier. But, we see two additional 1d KDE plots at the top and the right. What do these tell us? These tell us the marginal 1d distributions of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</p>
<p>The marginal distribution of <span class="math inline">\(X_1\)</span> is the distribution of <span class="math inline">\(X_1\)</span> considering all values of <span class="math inline">\(X_2\)</span> and vice versa. One of the interesting properties of Gaussian distributions is that the marginal distribution of a Gaussian is also a Gaussian distribution. MathematicalMonk on Youtube has a <a href="https://www.youtube.com/watch?v=ycDSJkZ_h0I">great set of lectures on this topic</a> that I would highly recommend!</p>
<p>What would you expect the marginal distribution of <span class="math inline">\(X_1\)</span> to look like? No prizes for guessing.</p>
<p>Given <span class="math display">\[
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
\mu_1 \\
\mu_2
\end{pmatrix} , \begin{pmatrix}
a &amp; \rho \\
\rho &amp; b
\end{pmatrix} \right)
\]</span></p>
<p>we have the marginal distribution of: <span class="math display">\[X_1 \sim \mathcal{N}(\mu_1, a)\]</span> and <span class="math display">\[X_2 \sim \mathcal{N}(\mu_2, b)\]</span></p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_jointplot_2d(a, b, rho):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> np.random.multivariate_normal(mean <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">0</span>]), cov <span class="op">=</span> np.array([[a, rho], [rho, b]]), size<span class="op">=</span>(<span class="dv">10000</span>, ))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    data_df <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>[<span class="vs">r'$X_1$'</span>,<span class="vs">r'$X_2$'</span>])</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    g <span class="op">=</span> sns.jointplot(x<span class="op">=</span> <span class="vs">r'$X_1$'</span>, y<span class="op">=</span><span class="vs">r'$X_2$'</span>, data<span class="op">=</span>data_df, kind<span class="op">=</span><span class="st">"reg"</span>,color<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
Ok, let us know try to plot a few jointplots for different covariance matrices. We would be passing in the values of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> and <span class="math inline">\(\rho\)</span> which would make up the covariance matrix as:
<span class="math display">\[\begin{pmatrix}
a &amp; \rho \\
\rho &amp; b
\end{pmatrix}\]</span>
<p>We would make these plots for mean zero.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plot_jointplot_2d(<span class="dv">1</span>, <span class="dv">1</span>, <span class="op">-</span><span class="fl">0.7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In the plot above, for <span class="math inline">\(a=1\)</span>, <span class="math inline">\(b=1\)</span> and <span class="math inline">\(\rho=0.7\)</span> we can see the negative correlation (but high) between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</p>
<p>Let us now increase the variance in <span class="math inline">\(X_1\)</span> and keep all other paramaters constant.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plot_jointplot_2d(<span class="dv">2</span>, <span class="dv">1</span>, <span class="op">-</span><span class="fl">0.7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>One can see from the plot above that the variance in <span class="math inline">\(X_1\)</span> is much higher now and the plot extends from -6 to +6 for <span class="math inline">\(X_1\)</span> while earlier it was restricted from -4 to 4.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>plot_jointplot_2d(<span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>One can see from the plot above that the correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> is zero.</p>
<section id="surface-plots-for-bi-variate-gaussian" class="level4">
<h4 class="anchored" data-anchor-id="surface-plots-for-bi-variate-gaussian">Surface plots for bi-variate Gaussian</h4>
<p>We will now look into surface plots for bi-variate Gaussian. This is yet another way to plot and understand Gaussian distributions. I borrow code from an <a href="https://scipython.com/blog/visualizing-the-bivariate-gaussian-distribution/">excellent tuorial</a> on plotting bivariate Gaussians.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> multivariate_normal</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_pdf_2d_gaussian(mu, sigma):</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    N <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, N)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>, N)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(X, Y)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pack X and Y into a single 3-dimensional array</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> np.empty(X.shape <span class="op">+</span> (<span class="dv">2</span>,))</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">0</span>] <span class="op">=</span> X</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">1</span>] <span class="op">=</span> Y</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, sigma)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> F.pdf(pos)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a surface plot and projected filled contour plot under it.</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure()</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> fig.gca(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    ax.plot_surface(X, Y, Z, rstride<span class="op">=</span><span class="dv">3</span>, cstride<span class="op">=</span><span class="dv">3</span>, linewidth<span class="op">=</span><span class="dv">1</span>, antialiased<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>                    cmap<span class="op">=</span>cm.Greys)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="vs">r"$X_1$"</span>)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="vs">r"$X_2$"</span>)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    ax.set_zlabel(<span class="st">"PDF"</span>)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    cset <span class="op">=</span> ax.contourf(X, Y, Z, zdir<span class="op">=</span><span class="st">'z'</span>, offset<span class="op">=-</span><span class="fl">0.15</span>, cmap<span class="op">=</span>cm.Greys)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Adjust the limits, ticks and view angle</span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    ax.set_zlim(<span class="op">-</span><span class="fl">0.15</span>,<span class="fl">0.25</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    ax.set_zticks(np.linspace(<span class="dv">0</span>,<span class="fl">0.2</span>,<span class="dv">5</span>))</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    ax.view_init(<span class="dv">27</span>, <span class="op">-</span><span class="dv">15</span>)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'$\mu$ = </span><span class="sc">{</span>mu<span class="sc">}</span><span class="ch">\n</span><span class="ss"> $\Sigma$ = </span><span class="sc">{</span>sigma<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.array([<span class="fl">0.</span>, <span class="fl">0.</span>])</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> np.array([[ <span class="fl">1.</span> , <span class="op">-</span><span class="fl">0.5</span>], [<span class="op">-</span><span class="fl">0.5</span>,  <span class="dv">1</span>]])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>make_pdf_2d_gaussian(mu, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
From the plot above, we can see the surface plot showing the probability density function for the Gaussian with mean
<span class="math display">\[\begin{pmatrix}
0 \\
0
\end{pmatrix}\]</span>
and covariance matrix:
<span class="math display">\[\begin{pmatrix}
1 &amp; -0.5 \\
-0.5 &amp; 1
\end{pmatrix}\]</span>
<p>It can be seen that the probability peaks arounds <span class="math inline">\(X_1=0\)</span> and <span class="math inline">\(X_2=0\)</span>. The bottom plot shows the same concept using contour plots which we will heavily use from now on. The different circles in the bottom contour plot denote the loci of same probability density. Since the contour plot requires a lesser dimension, it will be easier to use in our further analysis.</p>
<p>Also, from the contour plots, we can see the correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>.</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.array([<span class="fl">0.</span>, <span class="fl">0.</span>])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> np.array([[ <span class="fl">1.</span> , <span class="dv">0</span>], [<span class="dv">0</span>,  <span class="dv">1</span>]])</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>make_pdf_2d_gaussian(mu, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In the plot above, we can see that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are not correlated.</p>
</section>
<section id="contour-plots-for-2d-gaussians" class="level4">
<h4 class="anchored" data-anchor-id="contour-plots-for-2d-gaussians">Contour plots for 2D Gaussians</h4>
<p>Having seen the relationship between the surface plots and the contour plots, we will now exclusively focus on the contour plots. Here is a simple function to generate the contour plot for 2g gaussian with mean and covariance as the arguments.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_2d_contour_pdf(mu, sigma):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">60</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">60</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(X, Y)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pack X and Y into a single 3-dimensional array</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> np.empty(X.shape <span class="op">+</span> (<span class="dv">2</span>,))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">0</span>] <span class="op">=</span> X</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">1</span>] <span class="op">=</span> Y</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, sigma)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> F.pdf(pos)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="vs">r"$X_1$"</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="vs">r"$X_2$"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f'$\mu$ = </span><span class="sc">{</span>mu<span class="sc">}</span><span class="ch">\n</span><span class="ss"> $\Sigma$ = </span><span class="sc">{</span>sigma<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    plt.contourf(X, Y, Z, zdir<span class="op">=</span><span class="st">'z'</span>, offset<span class="op">=-</span><span class="fl">0.15</span>, cmap<span class="op">=</span>cm.Greys)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    plt.colorbar()</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.array([<span class="fl">0.</span>, <span class="fl">0.</span>])</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> np.array([[ <span class="fl">1.</span> , <span class="fl">0.5</span>], [<span class="fl">0.5</span>,  <span class="fl">1.</span>]])</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>plot_2d_contour_pdf(mu, sigma)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The plot above shows the contour plot for 2d gaussian with mean [0, 0] and covariance [[ 1. , 0.5], [0.5, 1.]]. We can see the correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span></p>
</section>
</section>
<section id="sample-from-2d-gaussian-and-visualising-it-on-xy-plane" class="level3">
<h3 class="anchored" data-anchor-id="sample-from-2d-gaussian-and-visualising-it-on-xy-plane">Sample from 2d gaussian and visualising it on XY plane</h3>
<p>We will now sample a point from a 2d Gaussian and describe a new way of visualising it.</p>
<p><img src="images/0.7/0.jpg" class="img-fluid"></p>
<ul>
<li><p>The left most plot shows the covariance matrix.</p></li>
<li><p>The middle plot shows the contour plot. The dark point marked in the contour plot is a sampled point (at random) from this 2d Gaussian distribution.</p></li>
<li><p>The right most plot is an alternative representation of the sampled point. The x-axis corresponds to the labels <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> and the corresponding y-axis are the coordinates of the point in the <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span> dimension shown in the contour plot.</p></li>
</ul>
<p>We will now write a function to generate a random sample from a 2d gaussian given it’s mean and covariance matrix.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_2d_contour_pdf_dimensions(mu, sigma, random_num):</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">60</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">60</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(X, Y)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pack X and Y into a single 3-dimensional array</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> np.empty(X.shape <span class="op">+</span> (<span class="dv">2</span>,))</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">0</span>] <span class="op">=</span> X</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">1</span>] <span class="op">=</span> Y</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, sigma)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> F.pdf(pos)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(sigma, ax<span class="op">=</span>ax[<span class="dv">0</span>], annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].contour(X, Y, Z, cmap<span class="op">=</span>cm.Greys)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].scatter(random_point[<span class="dv">0</span>], random_point[<span class="dv">1</span>], color<span class="op">=</span><span class="st">'k'</span>,s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$X_1$"</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_ylabel(<span class="vs">r"$X_2$"</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>[<span class="st">'X1'</span>,<span class="st">'X2'</span>])</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax[<span class="dv">2</span>], kind<span class="op">=</span><span class="st">'line'</span>, marker<span class="op">=</span><span class="st">'o'</span>,color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">0</span>])</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">1</span>])</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">2</span>])</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">"Covariance Matrix"</span>)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_title(<span class="st">"Contour of pdf"</span>)</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].set_title(<span class="st">"Visualising the point"</span>)</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images"</span>):</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images"</span>)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="ss">f"images/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>):</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="ss">f"images/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>    plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will now create 20 such samples and animate them</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>    plot_2d_contour_pdf_dimensions( mu, np.array([[ <span class="fl">1.</span> , <span class="fl">0.1</span>], [<span class="fl">0.1</span>,  <span class="fl">1.</span>]]), i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="fl">0.1</span><span class="op">/*</span>.jpg sigma<span class="op">-</span><span class="dv">0</span><span class="op">-</span><span class="fl">1.</span><span class="er">gif</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="sigma-0-1.gif" class="img-fluid"></p>
<p>Since the correlation between the two variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> was low (0.1), we can the see that rightmost plot jumping a lot, i.e.&nbsp;to say that the values of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are not tighly constrained to move together.</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    plot_2d_contour_pdf_dimensions( mu, np.array([[ <span class="fl">1.</span> , <span class="fl">0.7</span>], [<span class="fl">0.7</span>,  <span class="fl">1.</span>]]), i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="fl">0.7</span><span class="op">/*</span>.jpg sigma<span class="op">-</span><span class="dv">0</span><span class="op">-</span><span class="fl">7.</span><span class="er">gif</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="sigma-0-7.gif" class="img-fluid"></p>
<p>The above GIF shows the same plot/animation for the 2d Gaussian where the correlation between the two variables is high (0.7). Thus, we can see that the two variables tend to move up and down together.</p>
</section>
<section id="conditional-bivariate-distribution" class="level3">
<h3 class="anchored" data-anchor-id="conditional-bivariate-distribution">Conditional Bivariate Distribution</h3>
<p>All excellent till now. Now, let us move to the case in which some variable’s values are known. We would then look to find the distribution of the other variables conditional on the value of the known variable. I borrow some text from Wikipedia on the subject.</p>
<p><span class="math display">\[
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
0 \\
0
\end{pmatrix} , \begin{pmatrix}
1 &amp; \rho \\
\rho &amp; 1
\end{pmatrix} \right)
\]</span></p>
<p>The conditional expectation of <span class="math inline">\(X_2\)</span> given <span class="math inline">\(X_1\)</span> is: $(X_2 X_1=x_1)= x_1 $</p>
<p>and the conditional variance is: <span class="math inline">\(\operatorname{var}(X_2 \mid X_1 = x_1) = 1-\rho^2\)</span></p>
<p>So, the question now is: suppose we fix <span class="math inline">\(X_1 = 1\)</span>, what is the distribution of <span class="math inline">\(X_2\)</span>. Again, Gaussians are amazing - the conditional distributionon is again a Gaussian. Let us make some plots to understand better. The following plots would be showing the distribution of <span class="math inline">\(X_2\)</span> with fixed <span class="math inline">\(X_1\)</span></p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_2d_contour_pdf_dimensions_fixed_x1(sigma, random_num, x1 <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> np.zeros(<span class="dv">2</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">60</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">60</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    X, Y <span class="op">=</span> np.meshgrid(X, Y)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pack X and Y into a single 3-dimensional array</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> np.empty(X.shape <span class="op">+</span> (<span class="dv">2</span>,))</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">0</span>] <span class="op">=</span> X</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    pos[:, :, <span class="dv">1</span>] <span class="op">=</span> Y</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, sigma)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> F.pdf(pos)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    rho <span class="op">=</span> sigma[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    F_cond_x1 <span class="op">=</span> multivariate_normal(rho<span class="op">*</span>x1, <span class="dv">1</span><span class="op">-</span>rho<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    random_point_x2 <span class="op">=</span> F_cond_x1.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(sigma, ax<span class="op">=</span>ax[<span class="dv">0</span>], annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].contour(X, Y, Z, cmap<span class="op">=</span>cm.Greys)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].scatter(x1, random_point_x2, color<span class="op">=</span><span class="st">'k'</span>,s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_xlabel(<span class="vs">r"$X_1$"</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_ylabel(<span class="vs">r"$X_2$"</span>)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series([x1, random_point_x2], index<span class="op">=</span>[<span class="st">'X1'</span>,<span class="st">'X2'</span>])</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax[<span class="dv">2</span>], kind<span class="op">=</span><span class="st">'line'</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].scatter(x<span class="op">=</span><span class="dv">0</span>, y<span class="op">=</span>x1, color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].scatter(x<span class="op">=</span><span class="dv">1</span>, y<span class="op">=</span>random_point_x2, color<span class="op">=</span><span class="st">'k'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">0</span>])</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">1</span>])</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    format_axes(ax[<span class="dv">2</span>])</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">"Covariance Matrix"</span>)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_title(<span class="st">"Contour of pdf"</span>)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">2</span>].set_title(<span class="st">"Visualising the point"</span>)</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/conditional/"</span>):</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images/conditional/"</span>)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="ss">f"images/conditional/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>):</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="ss">f"images/conditional/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/conditional/</span><span class="sc">{</span>sigma[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>    plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    plot_2d_contour_pdf_dimensions_fixed_x1(np.array([[ <span class="fl">1.</span> , <span class="fl">0.1</span>], [<span class="fl">0.1</span>,  <span class="fl">1.</span>]]), i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span>conditional<span class="op">/</span><span class="fl">0.1</span><span class="op">/*</span>.jpg conditional<span class="op">-</span>sigma<span class="op">-</span><span class="dv">0</span><span class="op">-</span><span class="fl">1.</span><span class="er">gif</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="conditional-sigma-0-1.gif" class="img-fluid"></p>
<p>The above animation shows the movement of <span class="math inline">\(X_2\)</span> with <span class="math inline">\(X_1=1\)</span>. The <span class="math inline">\(X_1=1\)</span> is shown in red in the righmost plot. In the middle plot, we can confirm that the movement is only in the <span class="math inline">\(X_2\)</span> dimension. Further, since the correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> is weak, the righmost plot seems to wiggle or jump a lot!</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    plot_2d_contour_pdf_dimensions_fixed_x1(np.array([[ <span class="fl">1.</span> , <span class="fl">0.7</span>], [<span class="fl">0.7</span>,  <span class="fl">1.</span>]]), i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span>conditional<span class="op">/</span><span class="fl">0.7</span><span class="op">/*</span>.jpg conditional<span class="op">-</span>sigma<span class="op">-</span><span class="dv">0</span><span class="op">-</span><span class="fl">7.</span><span class="er">gif</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="conditional-sigma-0-7.gif" class="img-fluid"></p>
<p>In the plot above, we repeat the same p|rocedure but with a covariance matrix having a much higher correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. From the righmost plot, we can clearly see that the jumps in <span class="math inline">\(X2\)</span> are far lesser. This is expected, since the two variables are correlated!</p>
<section id="visualising-the-same-procedure-for-5-dimensional-gaussian" class="level4">
<h4 class="anchored" data-anchor-id="visualising-the-same-procedure-for-5-dimensional-gaussian">Visualising the same procedure for 5 dimensional Gaussian</h4>
<p>We will now repeat the same procedure we did for 2d case in 5 dimensions.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>covariance_5d <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>, <span class="fl">0.6</span>, <span class="fl">0.4</span>],</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>                          [<span class="fl">0.9</span>, <span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>, <span class="fl">0.6</span>],</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                          [<span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="dv">1</span>, <span class="fl">0.9</span>, <span class="fl">0.8</span>],</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                          [<span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="dv">1</span>, <span class="fl">0.9</span>],</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>                          [<span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="dv">1</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_5d_contour_pdf_dimensions(cov, random_num):</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> np.zeros(<span class="dv">5</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, cov)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cov, ax<span class="op">=</span>ax[<span class="dv">0</span>], annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>[<span class="st">'X1'</span>,<span class="st">'X2'</span>,<span class="st">'X3'</span>,<span class="st">'X4'</span>, <span class="st">'X5'</span>])</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax[<span class="dv">1</span>], kind<span class="op">=</span><span class="st">'line'</span>, marker<span class="op">=</span><span class="st">'o'</span>,color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>        format_axes(ax[i])</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">"Covariance Matrix"</span>)</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    ax[<span class="op">-</span><span class="dv">1</span>].set_title(<span class="st">"Visualising the point"</span>)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/5d/"</span>):</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images/5d"</span>)</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/5d/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>plot_5d_contour_pdf_dimensions(covariance_5d, <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    plot_5d_contour_pdf_dimensions(covariance_5d, i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="dv">5</span><span class="er">d</span><span class="op">/*</span>.jpg <span class="dv">5</span><span class="er">d</span>.gif</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="5d.gif" class="img-fluid"></p>
<p>From the visualisation above we can see that:</p>
<ul>
<li>since X1 and X2 are highly correlated, they move up and down together</li>
<li>but, X1 and X5 have low correlation, thus, they can seem to wiggle almost independently of each other.</li>
</ul>
<p>We are now getting somewhere. If the correlation between the variables is very high, we will get a smooth curve joining them. Right? Almost getting to the point where we can draw the introductory plot shown at the top of the post.</p>
</section>
</section>
<section id="conditional-multivariate-distribution" class="level3">
<h3 class="anchored" data-anchor-id="conditional-multivariate-distribution">Conditional Multivariate Distribution</h3>
<p>Ok, now let us draw the conditional distribution over this higher 5d space. We will fix the values of some of the variables and see the distribution of the others.</p>
<p>Borrowing from Wikipedia</p>
<p>If <span class="math inline">\(N\)</span>-dimensional <span class="math inline">\(x\)</span> is partitioned as follows</p>
<p><span class="math display">\[
\mathbf{x}
=
\begin{bmatrix}
\mathbf{x}_A \\
\mathbf{x}_B
\end{bmatrix}
\text{ with sizes }\begin{bmatrix} q \times 1 \\ (N-q) \times 1 \end{bmatrix}
\]</span></p>
<p>and accordingly <span class="math inline">\(μ\)</span> and <span class="math inline">\(Σ\)</span> are partitioned as follows</p>
<p><span class="math display">\[
\boldsymbol\mu
=
\begin{bmatrix}
\boldsymbol\mu_A \\
\boldsymbol\mu_B
\end{bmatrix}
\text{ with sizes }\begin{bmatrix} q \times 1 \\ (N-q) \times 1 \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\boldsymbol\Sigma
=
\begin{bmatrix}
\boldsymbol\Sigma_{AA} &amp; \boldsymbol\Sigma_{AB} \\
\boldsymbol\Sigma_{BA} &amp; \boldsymbol\Sigma_{BB}
\end{bmatrix}
\text{ with sizes }\begin{bmatrix} q \times q &amp; q \times (N-q) \\ (N-q) \times q &amp; (N-q) \times (N-q) \end{bmatrix}
\]</span></p>
<p>then the distribution of <span class="math inline">\(x_A\)</span> conditional on <span class="math inline">\(x_B=b\)</span> is multivariate normal <span class="math inline">\((x_A|x_B=b)\sim \mathcal{N}(\bar{\mu}, \bar{\Sigma})\)</span></p>
<p><span class="math display">\[
\bar{\boldsymbol\mu}
=
\boldsymbol\mu_A + \boldsymbol\Sigma_{AB} \boldsymbol\Sigma_{BB}^{-1}
\left(
\mathbf{B} - \boldsymbol\mu_B
\right)
\]</span></p>
<p>and covariance matrix</p>
<p><span class="math display">\[
\overline{\boldsymbol\Sigma}
=
\boldsymbol\Sigma_{AA} - \boldsymbol\Sigma_{AB} \boldsymbol\Sigma_{BB}^{-1} \boldsymbol\Sigma_{BA}.
\]</span></p>
<p>Let us for our example take <span class="math inline">\(X_5 = -2\)</span>.</p>
<p>We have:</p>
<p><span class="math inline">\(x_A = [x_1, x_2, x_3, x_4]\)</span> and <span class="math inline">\(x_B = [x_5]\)</span></p>
<p>Assuming the covariance matrix of size 5 X 5 is referred as <span class="math inline">\(C\)</span></p>
<p><span class="math display">\[
\boldsymbol\Sigma_{AA}
=
\begin{bmatrix}
C_{11} &amp; C_{12} &amp; C_{13} &amp; C_{14}\\
C_{21} &amp; C_{22} &amp; C_{23} &amp; C_{24}\\
C_{31} &amp; C_{32} &amp; C_{33} &amp; C_{34}\\
C_{41} &amp; C_{42} &amp; C_{43} &amp; C_{44}\\
\end{bmatrix} \\
\]</span></p>
<p><span class="math display">\[
\boldsymbol\Sigma_{AB}
=
\begin{bmatrix}
C_{15}\\
C_{25}\\
C_{35}\\
C_{45}\\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\boldsymbol\Sigma_{BA}
=
\begin{bmatrix}
C_{51}&amp; C_{52} &amp; C_{53} &amp; C_{54}\\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\boldsymbol\Sigma_{BB}
=
\begin{bmatrix}
C_{55}\\
\end{bmatrix}
\]</span></p>
<p>Putting in the numbers we get:</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>sigma_AA <span class="op">=</span> covariance_5d[:<span class="dv">4</span>, :<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>sigma_AA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>array([[1. , 0.9, 0.8, 0.6],
       [0.9, 1. , 0.9, 0.8],
       [0.8, 0.9, 1. , 0.9],
       [0.6, 0.8, 0.9, 1. ]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>sigma_AB <span class="op">=</span> covariance_5d[:<span class="dv">4</span>, <span class="dv">4</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>sigma_AB</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>array([[0.4],
       [0.6],
       [0.8],
       [0.9]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>sigma_BA <span class="op">=</span> covariance_5d[<span class="dv">4</span>, :<span class="dv">4</span>].reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>sigma_BA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>array([[0.4, 0.6, 0.8, 0.9]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>sigma_BB <span class="op">=</span> covariance_5d[<span class="dv">4</span>, <span class="dv">4</span>].reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>sigma_BB</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>array([[1.]])</code></pre>
</div>
</div>
<p>Now, calculating <span class="math inline">\(\bar{\mu}\)</span></p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>mu_bar <span class="op">=</span> np.zeros((<span class="dv">4</span>, <span class="dv">1</span>)) <span class="op">+</span> sigma_AB<span class="op">@</span>np.linalg.inv(sigma_BB)<span class="op">*</span>(<span class="op">-</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>mu_bar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>array([[-0.8],
       [-1.2],
       [-1.6],
       [-1.8]])</code></pre>
</div>
</div>
<p>Since, <span class="math inline">\(x_5\)</span> has highest correlation with <span class="math inline">\(x_4\)</span> it makes sense for <span class="math inline">\(x_5=-2\)</span> to have the mean of <span class="math inline">\(x_4\)</span> to be close to -2.</p>
<p>Now, calculating <span class="math inline">\(\bar{\Sigma}\)</span></p>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>sigma_bar <span class="op">=</span> sigma_AA <span class="op">-</span> sigma_AB<span class="op">@</span>np.linalg.inv(sigma_BB)<span class="op">@</span>sigma_BA</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>sigma_bar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>array([[0.84, 0.66, 0.48, 0.24],
       [0.66, 0.64, 0.42, 0.26],
       [0.48, 0.42, 0.36, 0.18],
       [0.24, 0.26, 0.18, 0.19]])</code></pre>
</div>
</div>
<p>Now, we have the new mean and covariance matrices for <span class="math inline">\(x_A = [x_1, x_2, x_3, x_4]\)</span> and <span class="math inline">\(x_B = [x_5] = [-2]\)</span>. Let us now draw some samples fixing <span class="math inline">\(x_5 = -2\)</span></p>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> sigma_bar</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> mu_bar.flatten()</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_5d_samples_fixed_x2(random_num):</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">3</span>))</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu, cov)</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(cov, ax<span class="op">=</span>ax[<span class="dv">0</span>], annot<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>[<span class="st">'X1'</span>,<span class="st">'X2'</span>,<span class="st">'X3'</span>,<span class="st">'X4'</span>])</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X5'</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">2</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax[<span class="dv">1</span>], kind<span class="op">=</span><span class="st">'line'</span>, marker<span class="op">=</span><span class="st">'.'</span>,color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a>    plt.scatter([<span class="dv">4</span>], [<span class="op">-</span><span class="dv">2</span>], color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a>        format_axes(ax[i])</span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">"Covariance Matrix"</span>)</span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a>    ax[<span class="op">-</span><span class="dv">1</span>].set_title(<span class="st">"Visualising the point"</span>)</span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/5d/conditional/1"</span>):</span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images/5d/conditional/1"</span>)</span>
<span id="cb58-29"><a href="#cb58-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb58-30"><a href="#cb58-30" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/5d/conditional/1/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb58-31"><a href="#cb58-31" aria-hidden="true" tabindex="-1"></a>    plt.close()</span>
<span id="cb58-32"><a href="#cb58-32" aria-hidden="true" tabindex="-1"></a>    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>    plot_5d_samples_fixed_x2(i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="dv">5</span><span class="er">d</span><span class="op">/</span>conditional<span class="op">/</span><span class="dv">1</span><span class="op">/*</span>.jpg <span class="dv">5</span><span class="er">d</span><span class="op">-</span>conditional<span class="op">-</span><span class="fl">1.</span><span class="er">gif</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="5d-conditional-1.gif" class="img-fluid"></p>
</section>
<section id="lets-increase-to-20-dimensions-now" class="level3">
<h3 class="anchored" data-anchor-id="lets-increase-to-20-dimensions-now">Let’s increase to 20 dimensions now!</h3>
<p>We can not surely write the covariance matrix for 20 dimensions. Let us use a small trick called the kernel function to create this matrix. We will come it later. For now, let us think of this function as a function which:</p>
<ul>
<li>outputs low numbers for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> if they differ by a lot</li>
<li>outputs high number for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> if they are very close</li>
</ul>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rbf_kernel(x_1, x_2, sig):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.exp((<span class="op">-</span>(x_1<span class="op">-</span>x_2)<span class="op">**</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">2</span><span class="op">*</span>(sig<span class="op">**</span><span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>rbf_kernel(<span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>1.0</code></pre>
</div>
</div>
<p>Since 1=1, the above function evaluates to 1 showing that 1 is similar to 1</p>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>rbf_kernel(<span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>0.9231163463866358</code></pre>
</div>
</div>
<p>Since 1 and 2 are close, the function above evaluates to close to 1</p>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>rbf_kernel(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>0.6065306597126334</code></pre>
</div>
</div>
<p>Ok, we use the same first two arguments 1 and 2 but change the last one to 1 from 0.4 and we see that the function evaluates to a much smaller number. Thus, we can see that increase the <code>sig</code> parameter leads to quicker dropoff in similarity between pair of points. Or, in other words, higher <code>sig</code> means that the influence of a point <code>x_1</code> reduces quicker.</p>
<p>Let us now create the covariance matrix of size (20, 20) using this kernel function.</p>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> np.zeros((<span class="dv">20</span>, <span class="dv">20</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>        C[i, j] <span class="op">=</span> rbf_kernel(i, j, <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us plot the heatmap of the covariance matrix</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(C)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d11ccbee0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-58-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The above heatmap confirms that there is correlation between nearby points, but close to zero or zero correlation otherwise.</p>
<section id="let-us-draw-some-samples-from-this-20-dimensional-gaussian" class="level4">
<h4 class="anchored" data-anchor-id="let-us-draw-some-samples-from-this-20-dimensional-gaussian">Let us draw some samples from this 20 dimensional Gaussian</h4>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_20d_samples(random_num):</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(np.zeros(<span class="dv">20</span>), C)</span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> [<span class="ss">f'X</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">21</span>)]</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>index)</span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax, kind<span class="op">=</span><span class="st">'line'</span>, marker<span class="op">=</span><span class="st">'.'</span>,color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb72-11"><a href="#cb72-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-12"><a href="#cb72-12" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb72-13"><a href="#cb72-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb72-14"><a href="#cb72-14" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb72-15"><a href="#cb72-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/20d/"</span>):</span>
<span id="cb72-16"><a href="#cb72-16" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images/20d/"</span>)</span>
<span id="cb72-17"><a href="#cb72-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb72-18"><a href="#cb72-18" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb72-19"><a href="#cb72-19" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/20d/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb72-20"><a href="#cb72-20" aria-hidden="true" tabindex="-1"></a>    plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>    plot_20d_samples(i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="dv">20</span><span class="er">d</span><span class="op">/*</span>.jpg <span class="dv">20</span><span class="er">d</span>.gif</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="20d.gif" class="img-fluid"></p>
<p>From the animation above, we can see different family of functions of mean zero across these 20 points. We’re really getting close now!</p>
</section>
<section id="let-us-now-condition-on-a-few-elements" class="level4">
<h4 class="anchored" data-anchor-id="let-us-now-condition-on-a-few-elements">Let us now condition on a few elements</h4>
<p>We will create a new ordering of these variables such that the known variables occur towards the end. This allows for easy calculations for conditioning.</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>order <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">15</span>, <span class="dv">16</span>, <span class="dv">17</span>, <span class="dv">18</span>, <span class="dv">19</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>new_C <span class="op">=</span> np.zeros_like(C)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>old_order <span class="op">=</span> <span class="bu">range</span>(<span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>        new_C[i, j] <span class="op">=</span> C[order[i], order[j]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(new_C, xticklabels<span class="op">=</span>order, yticklabels<span class="op">=</span>order, cmap<span class="op">=</span><span class="st">'jet'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d10b88d00&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-66-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Now, we can condition on (x1 = 1, x2 = 3, x6 = -3, X11 = 1). We will use the same procedure we used above in the case of 5d.</p>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="dv">1</span>]).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>B</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>array([[ 1],
       [ 3],
       [-3],
       [ 1]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>sigma_AA_20d <span class="op">=</span> new_C[:<span class="op">-</span>B.size, :<span class="op">-</span>B.size]</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>sigma_AA_20d.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>(16, 16)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>sigma_BB_20d <span class="op">=</span> new_C[<span class="op">-</span>B.size:, <span class="op">-</span>B.size:]</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>sigma_BB_20d.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>(4, 4)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>sigma_AB_20d <span class="op">=</span> new_C[:<span class="op">-</span>B.size, <span class="op">-</span>B.size:]</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>sigma_AB_20d.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>(16, 4)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>sigma_BA_20d <span class="op">=</span> new_C[<span class="op">-</span>B.size:, :<span class="op">-</span>B.size]</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>sigma_BA_20d.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>(4, 16)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>mu_bar_20d <span class="op">=</span> np.zeros((<span class="dv">20</span><span class="op">-</span>B.size, <span class="dv">1</span>)) <span class="op">+</span> sigma_AB_20d<span class="op">@</span>np.linalg.inv(sigma_BB_20d)<span class="op">@</span>(B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>sigma_bar_20d <span class="op">=</span> sigma_AA_20d <span class="op">-</span> sigma_AB_20d<span class="op">@</span>np.linalg.inv(sigma_BB_20d)<span class="op">@</span>sigma_BA_20d</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>sns.heatmap(sigma_bar_20d, xticklabels<span class="op">=</span>order[:<span class="op">-</span>B.size], yticklabels<span class="op">=</span>order[:<span class="op">-</span>B.size], cmap<span class="op">=</span><span class="st">'jet'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d091fd0a0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-74-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_20d_samples_known_x(random_num):</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>    fig, ax  <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> [<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> order[:<span class="op">-</span>B.size]]</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>index)</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X1'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X2'</span>] <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X6'</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X11'</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> data_array[[<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>)]]</span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>    data_array.plot(ax<span class="op">=</span>ax, kind<span class="op">=</span><span class="st">'line'</span>, marker<span class="op">=</span><span class="st">'.'</span>,color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>    plt.scatter([<span class="dv">0</span>, <span class="dv">1</span>,<span class="dv">5</span>, <span class="dv">10</span>], [<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>,s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a>    plt.suptitle(<span class="ss">f"Random state = </span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">"</span>, y<span class="op">=</span><span class="fl">1.1</span>)</span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/20d/conditional/"</span>):</span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>        os.makedirs(<span class="st">"images/20d/conditional/"</span>)</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a>    plt.grid()</span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="ss">f"images/20d/conditional/</span><span class="sc">{</span>random_num<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a>    plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">50</span>):</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>    plot_20d_samples_known_x(i)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">20</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="dv">20</span><span class="er">d</span><span class="op">/</span>conditional<span class="op">/*</span>.jpg <span class="dv">20</span><span class="er">d</span><span class="op">-</span>conditional.gif</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="20d-conditional.gif" class="img-fluid"></p>
<p>From the plot above, we can see the known points in red and the other points wiggle to show the families of functions that we fit. Let us now draw a lot of samples and plot the mean and variance in these samples for the unknown X variables. We could have obtained the mean and variance directly using Gaussian marginalisation, but, for now let us just draw many samples.</p>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>dfs <span class="op">=</span> {}</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> random_num <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a>    random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> [<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> order[:<span class="op">-</span>B.size]]</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>index)</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X1'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X2'</span>] <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X6'</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">3</span></span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a>    data_array[<span class="st">'X11'</span>] <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>    data_array <span class="op">=</span> data_array[[<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>)]]</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>    dfs[random_num] <span class="op">=</span> data_array</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(dfs).mean(axis<span class="op">=</span><span class="dv">1</span>).plot(yerr<span class="op">=</span>pd.DataFrame(dfs).std(axis<span class="op">=</span><span class="dv">1</span>),marker<span class="op">=</span><span class="st">'o'</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>plt.scatter([<span class="dv">0</span>, <span class="dv">1</span>,<span class="dv">5</span>, <span class="dv">10</span>], [<span class="dv">1</span>, <span class="dv">3</span>, <span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>,s<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d0fcc8d00&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-79-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>From the plot above, we can see the uncertainty (standard deviation) and the mean values for different variables. As expected, the uncertainty close to the known points (red) is low. Also, owing to the smooth nature of the covariance function we can see the means of unknown points close to known points are fairly similar.</p>
<p>To summarise: We can very clearly see that there is low variance in zones where we have the known values and high variance otherwise. The farther we go away from a known value, the more is the variance!</p>
</section>
</section>
<section id="kernels" class="level3">
<h3 class="anchored" data-anchor-id="kernels">Kernels!</h3>
<p>We will now take a small plunge into the world of kernels. As mentioned earlier, we will limit the discussion to generating to covariance matrix.</p>
<p>We will be redefining the function mentioned above to include two parameters <code>l</code> and <code>s</code></p>
<ul>
<li><code>s</code> is the scale of variance</li>
<li><code>l</code> is the influence of the point to neighbouring points</li>
</ul>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sig(x1, x2, l, s):</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>(np.exp((<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">*</span>(l<span class="op">**</span><span class="dv">2</span>))<span class="op">*</span>((x1<span class="op">-</span>x2)<span class="op">**</span><span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>Cov_matrix <span class="op">=</span> np.zeros((<span class="dv">100</span>, <span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">4</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ix, l <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="dv">1</span>]):</span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a>            Cov_matrix[i, j] <span class="op">=</span> sig(i, j, l, <span class="dv">1</span>)</span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a>    im <span class="op">=</span> ax[ix].imshow(Cov_matrix, cmap<span class="op">=</span><span class="st">'jet'</span>)</span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a>    ax[ix].set_title(<span class="ss">f"l=</span><span class="sc">{</span>l<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a>fig.subplots_adjust(right<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>cbar_ax <span class="op">=</span> fig.add_axes([<span class="fl">0.85</span>, <span class="fl">0.35</span>, <span class="fl">0.05</span>, <span class="fl">0.3</span>])</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a>fig.colorbar(im, cax<span class="op">=</span>cbar_ax)</span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f"Covariance matrix for varying l and s = </span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>Text(0.5, 0.98, 'Covariance matrix for varying l and s = 1')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-82-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>In the plot above, we can the covariance matrices for fixed <code>s=1</code> and varying <code>l</code>. It can be seen that for very low <code>l</code>, the correlations between far away points is also significant. At <code>l=1</code>, this ceases to be the case.</p>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">4</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">3</span>))</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ix, s <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>]):</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>            Cov_matrix[i, j] <span class="op">=</span> sig(i, j, <span class="fl">0.1</span>, s)</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    sns.heatmap(Cov_matrix, cmap<span class="op">=</span><span class="st">'jet'</span>, ax<span class="op">=</span>ax[ix])</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    ax[ix].set_title(<span class="ss">f"s=</span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Covariance matrix for varying s and l = 0.1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>Text(0.5, 0.98, 'Covariance matrix for varying s and l = 0.1')</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-83-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Ok, this is great. We can see the different scales on the colorbars with increasing <code>s</code> and fixing <code>l</code></p>
<p>Now, let us try and redo the 20 point dataset with varying kernel parameters with conditioning on some known data.</p>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit_plot_gp(kernel_s, kernel_l, known_data, total_data_points, save<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="co">    kernel_s: sigma^2 param of kernel</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="co">    kernel_l: l (width) param of kernel</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="co">    known_data: {pos: value}</span></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a><span class="co">    total_data_points</span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>    o <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">20</span>))</span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> known_data.keys():</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>        o.remove(key)</span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>    o.extend(<span class="bu">list</span>(known_data.keys()))</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> np.zeros((total_data_points, total_data_points))</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(total_data_points):</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(total_data_points):</span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a>            C[i, j] <span class="op">=</span> sig(i, j, kernel_l, kernel_s)</span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Making known variables shift</span></span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a>    new_C <span class="op">=</span> np.zeros_like(C)</span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a>            new_C[i, j] <span class="op">=</span> C[o[i], o[j]]</span>
<span id="cb107-24"><a href="#cb107-24" aria-hidden="true" tabindex="-1"></a>    B <span class="op">=</span> np.array(<span class="bu">list</span>(known_data.values())).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)    </span>
<span id="cb107-25"><a href="#cb107-25" aria-hidden="true" tabindex="-1"></a>    sigma_BA_20d <span class="op">=</span> new_C[<span class="op">-</span>B.size:, :<span class="op">-</span>B.size]</span>
<span id="cb107-26"><a href="#cb107-26" aria-hidden="true" tabindex="-1"></a>    sigma_AB_20d <span class="op">=</span> new_C[:<span class="op">-</span>B.size, <span class="op">-</span>B.size:]</span>
<span id="cb107-27"><a href="#cb107-27" aria-hidden="true" tabindex="-1"></a>    sigma_BB_20d <span class="op">=</span> new_C[<span class="op">-</span>B.size:, <span class="op">-</span>B.size:]</span>
<span id="cb107-28"><a href="#cb107-28" aria-hidden="true" tabindex="-1"></a>    sigma_AA_20d <span class="op">=</span> new_C[:<span class="op">-</span>B.size, :<span class="op">-</span>B.size]</span>
<span id="cb107-29"><a href="#cb107-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-30"><a href="#cb107-30" aria-hidden="true" tabindex="-1"></a>    mu_bar_20d <span class="op">=</span> np.zeros((<span class="dv">20</span><span class="op">-</span>B.size, <span class="dv">1</span>)) <span class="op">+</span> sigma_AB_20d<span class="op">@</span>np.linalg.inv(sigma_BB_20d)<span class="op">@</span>(B)</span>
<span id="cb107-31"><a href="#cb107-31" aria-hidden="true" tabindex="-1"></a>    sigma_bar_20d <span class="op">=</span> sigma_AA_20d <span class="op">-</span> sigma_AB_20d<span class="op">@</span>np.linalg.inv(sigma_BB_20d)<span class="op">@</span>sigma_BA_20d</span>
<span id="cb107-32"><a href="#cb107-32" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> multivariate_normal(mu_bar_20d.flatten(), sigma_bar_20d)</span>
<span id="cb107-33"><a href="#cb107-33" aria-hidden="true" tabindex="-1"></a>    dfs <span class="op">=</span> {}</span>
<span id="cb107-34"><a href="#cb107-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> random_num <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb107-35"><a href="#cb107-35" aria-hidden="true" tabindex="-1"></a>        random_point <span class="op">=</span> F.rvs(random_state<span class="op">=</span>random_num)</span>
<span id="cb107-36"><a href="#cb107-36" aria-hidden="true" tabindex="-1"></a>        index <span class="op">=</span> [<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> o[:<span class="op">-</span>B.size]]</span>
<span id="cb107-37"><a href="#cb107-37" aria-hidden="true" tabindex="-1"></a>        data_array <span class="op">=</span> pd.Series(random_point, index<span class="op">=</span>index)</span>
<span id="cb107-38"><a href="#cb107-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k, v <span class="kw">in</span> known_data.items():</span>
<span id="cb107-39"><a href="#cb107-39" aria-hidden="true" tabindex="-1"></a>            data_array[<span class="ss">f'X</span><span class="sc">{</span>k<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>] <span class="op">=</span> v</span>
<span id="cb107-40"><a href="#cb107-40" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb107-41"><a href="#cb107-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-42"><a href="#cb107-42" aria-hidden="true" tabindex="-1"></a>        data_array <span class="op">=</span> data_array[[<span class="ss">f'X</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>)]]</span>
<span id="cb107-43"><a href="#cb107-43" aria-hidden="true" tabindex="-1"></a>        dfs[random_num] <span class="op">=</span> data_array</span>
<span id="cb107-44"><a href="#cb107-44" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">3</span>))</span>
<span id="cb107-45"><a href="#cb107-45" aria-hidden="true" tabindex="-1"></a>    mean_vector <span class="op">=</span> pd.DataFrame(dfs).mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb107-46"><a href="#cb107-46" aria-hidden="true" tabindex="-1"></a>    mean_vector.plot(marker<span class="op">=</span><span class="st">'.'</span>, color<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb107-47"><a href="#cb107-47" aria-hidden="true" tabindex="-1"></a>    yerr<span class="op">=</span>pd.DataFrame(dfs).std(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb107-48"><a href="#cb107-48" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb107-49"><a href="#cb107-49" aria-hidden="true" tabindex="-1"></a>    plt.fill_between(<span class="bu">range</span>(<span class="bu">len</span>(mean_vector)), mean_vector<span class="op">+</span>yerr, mean_vector<span class="op">-</span>yerr, color<span class="op">=</span><span class="st">'gray'</span>,alpha<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb107-50"><a href="#cb107-50" aria-hidden="true" tabindex="-1"></a>    plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), data_array.index.values)</span>
<span id="cb107-51"><a href="#cb107-51" aria-hidden="true" tabindex="-1"></a>    plt.scatter(<span class="bu">list</span>(known_data.keys()), <span class="bu">list</span>(known_data.values()), color<span class="op">=</span><span class="st">'gray'</span>,s<span class="op">=</span><span class="dv">200</span>,zorder<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb107-52"><a href="#cb107-52" aria-hidden="true" tabindex="-1"></a>    format_axes(plt.gca())</span>
<span id="cb107-53"><a href="#cb107-53" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f" l = </span><span class="sc">{</span>kernel_l<span class="sc">}</span><span class="ss"> and s = </span><span class="sc">{</span>kernel_s<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb107-54"><a href="#cb107-54" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb107-55"><a href="#cb107-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> save:</span>
<span id="cb107-56"><a href="#cb107-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">"images/20d/conditional-points/"</span>):</span>
<span id="cb107-57"><a href="#cb107-57" aria-hidden="true" tabindex="-1"></a>            os.makedirs(<span class="st">"images/20d/conditional-points/"</span>)</span>
<span id="cb107-58"><a href="#cb107-58" aria-hidden="true" tabindex="-1"></a>        plt.grid()</span>
<span id="cb107-59"><a href="#cb107-59" aria-hidden="true" tabindex="-1"></a>        plt.xticks(np.arange(<span class="bu">len</span>(data_array.index)), np.arange(<span class="bu">len</span>(data_array.index)))</span>
<span id="cb107-60"><a href="#cb107-60" aria-hidden="true" tabindex="-1"></a>        plt.ylim(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb107-61"><a href="#cb107-61" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f"Known data: </span><span class="sc">{</span>known_data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb107-62"><a href="#cb107-62" aria-hidden="true" tabindex="-1"></a>        plt.savefig(<span class="ss">f"images/20d/conditional-points/</span><span class="sc">{</span><span class="bu">len</span>(known_data.keys())<span class="sc">}</span><span class="ss">.jpg"</span>, bbox_inches<span class="op">=</span><span class="st">"tight"</span>)</span>
<span id="cb107-63"><a href="#cb107-63" aria-hidden="true" tabindex="-1"></a>        plt.close()</span>
<span id="cb107-64"><a href="#cb107-64" aria-hidden="true" tabindex="-1"></a>        </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>known_d <span class="op">=</span> {<span class="dv">0</span>:<span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>:<span class="dv">3</span>, <span class="dv">9</span>:<span class="op">-</span><span class="dv">1</span>, <span class="dv">14</span>:<span class="op">-</span><span class="dv">1</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>fit_plot_gp(<span class="dv">1</span>, <span class="fl">0.5</span>, known_d, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-86-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The above plot shows the uncertainty and the family of functions for <code>l=0.5</code> and <code>s=1</code>.</p>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>fit_plot_gp(<span class="dv">5</span>, <span class="fl">0.5</span>, known_d, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-87-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Keeping <code>l=0.5</code>, the above plot shows how increasing <code>s</code> increases the uncertainty of estimation.</p>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>fit_plot_gp(<span class="dv">1</span>, <span class="dv">1</span>, known_d, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-88-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The above plot shows how increasing <code>l</code> reduces the influence between far away points.</p>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>fit_plot_gp(<span class="dv">1</span>, <span class="dv">100</span>, known_d, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-89-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The above plot increases <code>l</code> to a very large value. Seems to be just moving around the mean?</p>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>order_points_added <span class="op">=</span> np.random.choice(<span class="bu">range</span>(<span class="dv">20</span>), size<span class="op">=</span><span class="dv">9</span>, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> {}</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">9</span>):</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a>    k[order_points_added[i]] <span class="op">=</span> np.random.choice(<span class="bu">range</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>    fit_plot_gp(<span class="dv">1</span>, <span class="fl">0.5</span>, k, <span class="dv">20</span>, <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>convert <span class="op">-</span>delay <span class="dv">40</span> <span class="op">-</span>loop <span class="dv">0</span> images<span class="op">/</span><span class="dv">20</span><span class="er">d</span><span class="op">/</span>conditional<span class="op">-</span>points<span class="op">/*</span>.jpg <span class="dv">20</span><span class="er">d</span><span class="op">-</span>conditional<span class="op">-</span>main.gif</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us create a small animation where we keep on adding points and see how the uncertainty and estimation changes</p>
<p><img src="20d-conditional-main.gif" class="img-fluid"></p>
</section>
<section id="creating-a-scikit-learn-like-function-containing-fit-and-predict" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-scikit-learn-like-function-containing-fit-and-predict">Creating a scikit-learn like function containing <code>fit</code> and <code>predict</code></h3>
<p>I’ll now bring in the formal definitions, summarise the discussion and write a function akin to scikit-learn which can accept train data to estimate for test data.</p>
<section id="formally-defining-gps" class="level4">
<h4 class="anchored" data-anchor-id="formally-defining-gps">Formally defining GPs</h4>
<p>A Gaussian process is fully specified by a mean function <code>m(x)</code> and covariance function <code>K(x, x')</code> :</p>
<p><span class="math display">\[
f(x) \sim GP (m(x),K(x, x')
\]</span></p>
<p>Let us consider a case of noiseless GPs now</p>
</section>
<section id="noiseless-gps" class="level4">
<h4 class="anchored" data-anchor-id="noiseless-gps">Noiseless GPs</h4>
<p>Given train data <span class="math display">\[D = {(x_i, y_i), i = 1:N}\]</span></p>
<p>Given a test set <span class="math inline">\(X_{*}\)</span> of size $N_* d $ containing <span class="math inline">\(N_*\)</span> points in <span class="math inline">\({\rm I\!R}^d\)</span>, we want to predict function outputs <span class="math inline">\(y_{*}\)</span></p>
<p>We can write:</p>
<p><span class="math display">\[
\begin{pmatrix}
y \\
y_*
\end{pmatrix}  \sim \mathcal{N} \left( \begin{pmatrix}
\mu \\
\mu_*
\end{pmatrix} , \begin{pmatrix}
K &amp; K_* \\
K_*^T &amp; K_{**}
\end{pmatrix} \right)
\]</span></p>
<p>where</p>
<p><span class="math display">\[
K = Ker(X, X) \in {\rm I\!R}^{N\times N}\\
K_* = Ker(X, X_*) \in {\rm I\!R}^{N\times N_*}\\
K_{**} = Ker(X_*, X_*) \in {\rm I\!R}^{N_*\times N_*}\\
\]</span></p>
<p>We had previously used the kernel which we will continue to use</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sig(x1, x2, l, s):</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>(np.exp((<span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">*</span>(l<span class="op">**</span><span class="dv">2</span>))<span class="op">*</span>((x1<span class="op">-</span>x2)<span class="op">**</span><span class="dv">2</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can then write:</p>
<p><span class="math display">\[
p(y_*|X_*, X, y) \sim \mathcal{N}(\mu', \Sigma') \\
\mu' = \mu_* + K_*^TK^{-1}(x-\mu) \\
\Sigma' = K_{**} - K_*^TK^{-1}K_*
\]</span></p>
<div class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NoiselessGP_inversion:</span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, l<span class="op">=</span><span class="fl">0.1</span>, s<span class="op">=</span><span class="dv">1</span>, prior_mean<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb116-3"><a href="#cb116-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l <span class="op">=</span> l</span>
<span id="cb116-4"><a href="#cb116-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.s <span class="op">=</span> s     </span>
<span id="cb116-5"><a href="#cb116-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prior_mean <span class="op">=</span> prior_mean</span>
<span id="cb116-6"><a href="#cb116-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb116-7"><a href="#cb116-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> prior_sample(<span class="va">self</span>, x, n):</span>
<span id="cb116-8"><a href="#cb116-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb116-9"><a href="#cb116-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample GP on x</span></span>
<span id="cb116-10"><a href="#cb116-10" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb116-11"><a href="#cb116-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sample_k <span class="op">=</span> <span class="va">self</span>.create_cov_matrix(x, x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb116-12"><a href="#cb116-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb116-13"><a href="#cb116-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb116-14"><a href="#cb116-14" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb116-15"><a href="#cb116-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb116-16"><a href="#cb116-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> kernel(<span class="va">self</span>, a, b, l, s):</span>
<span id="cb116-17"><a href="#cb116-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb116-18"><a href="#cb116-18" aria-hidden="true" tabindex="-1"></a><span class="co">        Borrowed from Nando De Freita's lecture code</span></span>
<span id="cb116-19"><a href="#cb116-19" aria-hidden="true" tabindex="-1"></a><span class="co">        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py</span></span>
<span id="cb116-20"><a href="#cb116-20" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb116-21"><a href="#cb116-21" aria-hidden="true" tabindex="-1"></a>        sqdist <span class="op">=</span> np.<span class="bu">sum</span>(a<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> np.<span class="bu">sum</span>(b<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>np.dot(a, b.T)</span>
<span id="cb116-22"><a href="#cb116-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>np.exp(<span class="op">-</span><span class="fl">.5</span> <span class="op">*</span> (<span class="dv">1</span><span class="op">/</span>l) <span class="op">*</span> sqdist)</span>
<span id="cb116-23"><a href="#cb116-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb116-24"><a href="#cb116-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, train_x, train_y):</span>
<span id="cb116-25"><a href="#cb116-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_x <span class="op">=</span> train_x</span>
<span id="cb116-26"><a href="#cb116-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_y <span class="op">=</span> train_y</span>
<span id="cb116-27"><a href="#cb116-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N <span class="op">=</span> <span class="bu">len</span>(train_x)</span>
<span id="cb116-28"><a href="#cb116-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> <span class="va">self</span>.kernel(train_x, train_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb116-29"><a href="#cb116-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb116-30"><a href="#cb116-30" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb116-31"><a href="#cb116-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, test_x):</span>
<span id="cb116-32"><a href="#cb116-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N_star <span class="op">=</span> <span class="bu">len</span>(test_x)</span>
<span id="cb116-33"><a href="#cb116-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star <span class="op">=</span> <span class="va">self</span>.kernel(<span class="va">self</span>.train_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb116-34"><a href="#cb116-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star_star <span class="op">=</span> <span class="va">self</span>.kernel(test_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb116-35"><a href="#cb116-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_mu <span class="op">=</span> <span class="va">self</span>.prior_mean <span class="op">+</span> <span class="va">self</span>.K_star.T<span class="op">@</span>np.linalg.inv(<span class="va">self</span>.K)<span class="op">@</span>(<span class="va">self</span>.train_y<span class="op">-</span><span class="va">self</span>.prior_mean)</span>
<span id="cb116-36"><a href="#cb116-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_sigma <span class="op">=</span> <span class="va">self</span>.K_star_star <span class="op">-</span> <span class="va">self</span>.K_star.T<span class="op">@</span>np.linalg.inv(<span class="va">self</span>.K)<span class="op">@</span>self.K_star</span>
<span id="cb116-37"><a href="#cb116-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.posterior_mu, <span class="va">self</span>.posterior_sigma</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> NoiselessGP_inversion()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>train_x <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">4</span>, <span class="op">-</span><span class="dv">3</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]).reshape(<span class="dv">5</span>,<span class="dv">1</span>)</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>train_y <span class="op">=</span> np.sin(train_x)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a>test_x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">50</span>).reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a>test_y <span class="op">=</span> np.sin(test_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a>plt.plot(train_x, train_y,<span class="st">'ko-'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-95-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>clf.fit(train_x, train_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>posterior_mu, posterior_var <span class="op">=</span> clf.predict(test_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>plt.plot(test_x, clf.posterior_mu,<span class="st">'k'</span>,label<span class="op">=</span><span class="st">'Predicted'</span>,lw<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>plt.plot(test_x, test_y, <span class="st">'purple'</span>,label<span class="op">=</span><span class="st">'GT'</span>,lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>plt.plot(train_x, train_y, <span class="st">'ko'</span>,label<span class="op">=</span><span class="st">'Training Data'</span>)</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>plt.fill_between(test_x.flatten(), </span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>                 (clf.posterior_mu.flatten() <span class="op">-</span> clf.posterior_sigma.diagonal().flatten()),</span>
<span id="cb122-7"><a href="#cb122-7" aria-hidden="true" tabindex="-1"></a>                 (clf.posterior_mu.flatten() <span class="op">+</span> clf.posterior_sigma.diagonal().flatten()),</span>
<span id="cb122-8"><a href="#cb122-8" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.3</span></span>
<span id="cb122-9"><a href="#cb122-9" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb122-10"><a href="#cb122-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb122-11"><a href="#cb122-11" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d0f567340&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-98-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="cholesky-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="cholesky-decomposition">Cholesky decomposition</h3>
<p>We had previously used matrix inversion to do the computation for computing the posterior mean and variance in our GP. However, the matrices involved may be poorly conditioned and thus Cholesky decomposition is often favoured.</p>
<p>From Wikipedia, the Cholesky decomposition of a matrix <span class="math inline">\(A\)</span> is given as: <span class="math display">\[
\mathbf{A} = \mathbf{L L}^T
\]</span></p>
<p>where <span class="math inline">\(L\)</span> is a real lower triangular matrix.</p>
<p>We can thus re-write the posterior mean and covariance as:</p>
<p><span class="math display">\[
p(y_*|X_*, X, y) \sim \mathcal{N}(\mu', \Sigma') \\
K = LL^T \\
\]</span></p>
<p>We are now going to use the <code>\</code> as follows: if <span class="math inline">\(A\omega = B\)</span>, then <span class="math inline">\(\omega\)</span> = <span class="math inline">\(A\)</span> <code>\</code> <span class="math inline">\(B\)</span></p>
<p>We now have: <span class="math display">\[
\alpha = K^{-1}(x-\mu) \\
or, \alpha = {LL^T}^{-1}(x-\mu) \\
or, \alpha = L^{-T}L^{-1}(x-\mu) \\
Let, L^{-1}(x-\mu) = \gamma\\
Thus, L\gamma = x-\mu \\
Thus, \gamma = L \setminus (x-\mu)\\\
Thus, \alpha = L^{T} \setminus (L \setminus (x-\mu))
\]</span></p>
<p>In Python, the same can be written as:</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> np.linalg.cholesky(K)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> np.linalg.solve(L.T, np.linalg.solve(L, x<span class="op">-</span>mu))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Thus, we can find the posterior mean as: <span class="math display">\[
\mu' = \mu_* + K_*^T \alpha \\
\]</span></p>
<p>We also know that <span class="math display">\[
\Sigma' = K_{**} - K_*^TK^{-1}K_*
\]</span></p>
<p>Let us now define <span class="math display">\[
v = L \setminus K_{*}\\
or, v = L^{-1}K_{*}\\
Thus, v^{T} = K_{*}^TL^{-T}\\
Thus, v^{T}v = K_{*}^TL^{-T}L^{-1}K_{*}\\
Thus, v^{T}v = K_*^TK^{-1}K_* = K_{**} - \Sigma'
\]</span></p>
<p><span class="math display">\[
\Sigma' = K_{**} - v^{T}v
\]</span></p>
<p>Let us know rewrite the code with Cholesky decomposition.</p>
<div class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NoiselessGP_Cholesky:</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, l<span class="op">=</span><span class="fl">0.1</span>, s<span class="op">=</span><span class="dv">1</span>, prior_mean<span class="op">=</span><span class="dv">0</span>):</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l <span class="op">=</span> l</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.s <span class="op">=</span> s     </span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prior_mean <span class="op">=</span> prior_mean</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> prior_sample(<span class="va">self</span>, x, n):</span>
<span id="cb125-8"><a href="#cb125-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb125-9"><a href="#cb125-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample GP on x</span></span>
<span id="cb125-10"><a href="#cb125-10" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb125-11"><a href="#cb125-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sample_k <span class="op">=</span> <span class="va">self</span>.create_cov_matrix(x, x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb125-12"><a href="#cb125-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb125-13"><a href="#cb125-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb125-14"><a href="#cb125-14" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb125-15"><a href="#cb125-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb125-16"><a href="#cb125-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> kernel(<span class="va">self</span>, a, b, l, s):</span>
<span id="cb125-17"><a href="#cb125-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb125-18"><a href="#cb125-18" aria-hidden="true" tabindex="-1"></a><span class="co">        Borrowed from Nando De Freita's lecture code</span></span>
<span id="cb125-19"><a href="#cb125-19" aria-hidden="true" tabindex="-1"></a><span class="co">        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py</span></span>
<span id="cb125-20"><a href="#cb125-20" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb125-21"><a href="#cb125-21" aria-hidden="true" tabindex="-1"></a>        sqdist <span class="op">=</span> np.<span class="bu">sum</span>(a<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> np.<span class="bu">sum</span>(b<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>np.dot(a, b.T)</span>
<span id="cb125-22"><a href="#cb125-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>np.exp(<span class="op">-</span><span class="fl">.5</span> <span class="op">*</span> (<span class="dv">1</span><span class="op">/</span>l) <span class="op">*</span> sqdist)</span>
<span id="cb125-23"><a href="#cb125-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb125-24"><a href="#cb125-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, train_x, train_y):</span>
<span id="cb125-25"><a href="#cb125-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_x <span class="op">=</span> train_x</span>
<span id="cb125-26"><a href="#cb125-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_y <span class="op">=</span> train_y</span>
<span id="cb125-27"><a href="#cb125-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N <span class="op">=</span> <span class="bu">len</span>(train_x)</span>
<span id="cb125-28"><a href="#cb125-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> <span class="va">self</span>.kernel(train_x, train_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb125-29"><a href="#cb125-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.linalg.cholesky(<span class="va">self</span>.K)</span>
<span id="cb125-30"><a href="#cb125-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb125-31"><a href="#cb125-31" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb125-32"><a href="#cb125-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, test_x):</span>
<span id="cb125-33"><a href="#cb125-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N_star <span class="op">=</span> <span class="bu">len</span>(test_x)</span>
<span id="cb125-34"><a href="#cb125-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star <span class="op">=</span> <span class="va">self</span>.kernel(<span class="va">self</span>.train_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb125-35"><a href="#cb125-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star_star <span class="op">=</span> <span class="va">self</span>.kernel(test_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb125-36"><a href="#cb125-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> np.linalg.solve(<span class="va">self</span>.L.T, np.linalg.solve(<span class="va">self</span>.L, <span class="va">self</span>.train_y<span class="op">-</span><span class="va">self</span>.prior_mean))</span>
<span id="cb125-37"><a href="#cb125-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> np.linalg.solve(<span class="va">self</span>.L, <span class="va">self</span>.K_star)</span>
<span id="cb125-38"><a href="#cb125-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_mu <span class="op">=</span> <span class="va">self</span>.prior_mean <span class="op">+</span> <span class="va">self</span>.K_star.T<span class="op">@</span>self.alpha</span>
<span id="cb125-39"><a href="#cb125-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_sigma <span class="op">=</span> <span class="va">self</span>.K_star_star <span class="op">-</span> <span class="va">self</span>.v.T<span class="op">@</span>self.v</span>
<span id="cb125-40"><a href="#cb125-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.posterior_mu, <span class="va">self</span>.posterior_sigma</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> NoiselessGP_Cholesky()</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>clf.fit(train_x, train_y)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>posterior_mu_cholesky, posterior_var_cholesky <span class="op">=</span> clf.predict(test_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will now compare our Cholesky decomposition based decompostion with the earlier one.</p>
<div class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>np.allclose(posterior_mu_cholesky, posterior_mu)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>np.allclose(posterior_var_cholesky, posterior_var)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>True</code></pre>
</div>
</div>
<p>Ok, all looks good till now! Let us now move on to the case for Noisy GPs.</p>
</section>
<section id="noisy-gps" class="level3">
<h3 class="anchored" data-anchor-id="noisy-gps">Noisy GPs</h3>
<p>Previously, we had assumed a noiseless model, which is to say, for the observed data, we had: <span class="math display">\[y_i = f(x_i)\]</span></p>
<p>We now make the model more flexible by saying that there can be noise in the observed data as well, thus: <span class="math display">\[
y_i = f(x_i) + \epsilon \\
\epsilon \sim \mathcal{N}(0, \sigma_y^2)
\]</span></p>
<p>One of the main difference compared to the noiseless model would be that in the noisy model, we will have some uncertainty even about the training points.</p>
<p>Everything about our model remains the same, except for the change in the covariance matrix <span class="math inline">\(K\)</span> for the training points, which is now given as:</p>
<p><span class="math display">\[K_y = \sigma_y^2\mathbf{I_n} + K
\]</span></p>
<p>We can now rewrite the function as follows:</p>
<div class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb131"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NoisyGP:</span>
<span id="cb131-2"><a href="#cb131-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, l <span class="op">=</span> <span class="fl">0.1</span>, s <span class="op">=</span> <span class="dv">1</span>, prior_mean <span class="op">=</span> <span class="dv">0</span>, sigma_y <span class="op">=</span> <span class="dv">1</span>):</span>
<span id="cb131-3"><a href="#cb131-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.l <span class="op">=</span> l</span>
<span id="cb131-4"><a href="#cb131-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.s <span class="op">=</span> s     </span>
<span id="cb131-5"><a href="#cb131-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.prior_mean <span class="op">=</span> prior_mean</span>
<span id="cb131-6"><a href="#cb131-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sigma_y <span class="op">=</span> sigma_y</span>
<span id="cb131-7"><a href="#cb131-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb131-8"><a href="#cb131-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> prior_sample(<span class="va">self</span>, x, n):</span>
<span id="cb131-9"><a href="#cb131-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb131-10"><a href="#cb131-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample GP on x</span></span>
<span id="cb131-11"><a href="#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb131-12"><a href="#cb131-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sample_k <span class="op">=</span> <span class="va">self</span>.create_cov_matrix(x, x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb131-13"><a href="#cb131-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb131-14"><a href="#cb131-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb131-15"><a href="#cb131-15" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb131-16"><a href="#cb131-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb131-17"><a href="#cb131-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> kernel(<span class="va">self</span>, a, b, l, s):</span>
<span id="cb131-18"><a href="#cb131-18" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb131-19"><a href="#cb131-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Borrowed from Nando De Freita's lecture code</span></span>
<span id="cb131-20"><a href="#cb131-20" aria-hidden="true" tabindex="-1"></a><span class="co">        https://www.cs.ubc.ca/~nando/540-2013/lectures/gp.py</span></span>
<span id="cb131-21"><a href="#cb131-21" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb131-22"><a href="#cb131-22" aria-hidden="true" tabindex="-1"></a>        sqdist <span class="op">=</span> np.<span class="bu">sum</span>(a<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>).reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>) <span class="op">+</span> np.<span class="bu">sum</span>(b<span class="op">**</span><span class="dv">2</span>,<span class="dv">1</span>) <span class="op">-</span> <span class="dv">2</span><span class="op">*</span>np.dot(a, b.T)</span>
<span id="cb131-23"><a href="#cb131-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s<span class="op">**</span><span class="dv">2</span><span class="op">*</span>np.exp(<span class="op">-</span><span class="fl">.5</span> <span class="op">*</span> (<span class="dv">1</span><span class="op">/</span>l) <span class="op">*</span> sqdist)</span>
<span id="cb131-24"><a href="#cb131-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb131-25"><a href="#cb131-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, train_x, train_y):</span>
<span id="cb131-26"><a href="#cb131-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_x <span class="op">=</span> train_x</span>
<span id="cb131-27"><a href="#cb131-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_y <span class="op">=</span> train_y</span>
<span id="cb131-28"><a href="#cb131-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N <span class="op">=</span> <span class="bu">len</span>(train_x)</span>
<span id="cb131-29"><a href="#cb131-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> <span class="va">self</span>.kernel(train_x, train_x, <span class="va">self</span>.l, <span class="va">self</span>.s) <span class="op">+</span> <span class="va">self</span>.sigma_y<span class="op">*</span>np.eye(<span class="bu">len</span>(train_x))</span>
<span id="cb131-30"><a href="#cb131-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.L <span class="op">=</span> np.linalg.cholesky(<span class="va">self</span>.K)</span>
<span id="cb131-31"><a href="#cb131-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb131-32"><a href="#cb131-32" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb131-33"><a href="#cb131-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, test_x):</span>
<span id="cb131-34"><a href="#cb131-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N_star <span class="op">=</span> <span class="bu">len</span>(test_x)</span>
<span id="cb131-35"><a href="#cb131-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star <span class="op">=</span> <span class="va">self</span>.kernel(<span class="va">self</span>.train_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb131-36"><a href="#cb131-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K_star_star <span class="op">=</span> <span class="va">self</span>.kernel(test_x, test_x, <span class="va">self</span>.l, <span class="va">self</span>.s)</span>
<span id="cb131-37"><a href="#cb131-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alpha <span class="op">=</span> np.linalg.solve(<span class="va">self</span>.L.T, np.linalg.solve(<span class="va">self</span>.L, <span class="va">self</span>.train_y<span class="op">-</span><span class="va">self</span>.prior_mean))</span>
<span id="cb131-38"><a href="#cb131-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> np.linalg.solve(<span class="va">self</span>.L, <span class="va">self</span>.K_star)</span>
<span id="cb131-39"><a href="#cb131-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_mu <span class="op">=</span> <span class="va">self</span>.prior_mean <span class="op">+</span> <span class="va">self</span>.K_star.T<span class="op">@</span>self.alpha</span>
<span id="cb131-40"><a href="#cb131-40" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_sigma <span class="op">=</span> <span class="va">self</span>.K_star_star <span class="op">-</span> <span class="va">self</span>.v.T<span class="op">@</span>self.v</span>
<span id="cb131-41"><a href="#cb131-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.posterior_mu, <span class="va">self</span>.posterior_sigma</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> NoisyGP(sigma_y<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>clf.fit(train_x, train_y)</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>posterior_mu_noisy, posterior_var_noisy <span class="op">=</span> clf.predict(test_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb133"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>plt.plot(test_x, clf.posterior_mu,<span class="st">'k'</span>,label<span class="op">=</span><span class="st">'Predicted'</span>,lw<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a>plt.plot(test_x, test_y, <span class="st">'purple'</span>,label<span class="op">=</span><span class="st">'GT'</span>,lw<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>plt.plot(train_x, train_y, <span class="st">'ko'</span>,label<span class="op">=</span><span class="st">'Training Data'</span>)</span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>plt.fill_between(test_x.flatten(), </span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>                 (clf.posterior_mu.flatten() <span class="op">-</span> clf.posterior_sigma.diagonal().flatten()),</span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a>                 (clf.posterior_mu.flatten() <span class="op">+</span> clf.posterior_sigma.diagonal().flatten()),</span>
<span id="cb133-8"><a href="#cb133-8" aria-hidden="true" tabindex="-1"></a>                 color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.3</span></span>
<span id="cb133-9"><a href="#cb133-9" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb133-10"><a href="#cb133-10" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb133-11"><a href="#cb133-11" aria-hidden="true" tabindex="-1"></a>format_axes(plt.gca())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f9d11584550&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2019-08-20-Gaussian-Processes_files/figure-html/cell-105-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>We can now see that our model has some uncertainty even on the train points!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>