<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.245">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nipun Batra">
<meta name="description" content="A programming introduction to recommender systems using Keras!">

<title>blog - Recommender Systems in Keras</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Recommender Systems in Keras</h1>
                  <div>
        <div class="description">
          A programming introduction to recommender systems using Keras!
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">ML</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nipun Batra </p>
            </div>
    </div>
      
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#task" id="toc-task" class="nav-link active" data-scroll-target="#task"><strong>Task</strong></a></li>
  <li><a href="#peak-into-the-dataset" id="toc-peak-into-the-dataset" class="nav-link" data-scroll-target="#peak-into-the-dataset">Peak into the dataset</a></li>
  <li><a href="#train-test-split" id="toc-train-test-split" class="nav-link" data-scroll-target="#train-test-split">Train test split</a></li>
  <li><a href="#matrix-factorisation" id="toc-matrix-factorisation" class="nav-link" data-scroll-target="#matrix-factorisation">Matrix factorisation</a></li>
  <li><a href="#matrix-factorisation-in-keras" id="toc-matrix-factorisation-in-keras" class="nav-link" data-scroll-target="#matrix-factorisation-in-keras">Matrix factorisation in Keras</a></li>
  <li><a href="#non-negative-matrix-factorisation-nnmf-in-keras" id="toc-non-negative-matrix-factorisation-nnmf-in-keras" class="nav-link" data-scroll-target="#non-negative-matrix-factorisation-nnmf-in-keras">Non-negative Matrix factorisation (NNMF) in Keras</a></li>
  <li><a href="#neural-networks-for-recommendation" id="toc-neural-networks-for-recommendation" class="nav-link" data-scroll-target="#neural-networks-for-recommendation">Neural networks for recommendation</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>I have written a <a href="../nnmf-tensorflow.html">few</a> <a href="../nmf-autograd.html">posts</a> <a href="../nmf-cvx.html">earlier</a> <a href="../nmf-out-matrix.html">about</a> <a href="../mf-autograd-adagrad.html">matrix</a> <a href="../contrained-nmf-cvx.html">factorisation</a> <a href="../nmf-nnls.html">using</a> various Python libraries. The main application I had in mind for matrix factorisation was <a href="https://en.wikipedia.org/wiki/Recommender_system">recommender systems</a>. In this post, I’ll write about using <a href="https://keras.io">Keras</a> for creating recommender systems. <a href="https://github.com/maciejkula/triplet_recommendations_keras">Various</a> <a href="http://blog.richardweiss.org/2016/09/25/movie-embeddings.html">people</a> <a href="https://github.com/bradleypallen/keras-movielens-cf">have</a> <a href="https://github.com/hexiangnan/neural_collaborative_filtering">written</a> <a href="https://github.com/sonyisme/keras-recommendation">excellent</a> <a href="http://course.fast.ai/lessons/lesson4.html">similar</a> <a href="https://github.com/maciejkula/spotlight">posts</a> and code that I draw a lot of inspiration from, and give them their credit! I’m assuming that a reader has some experience with Keras, as this post is not intended to be an introduction to Keras.</p>
<p>Specifically, in this post, I’ll talk about:</p>
<ol type="1">
<li>Matrix Factorisation in Keras</li>
<li>Adding non-negativitiy constraints to solve non-negative matrix factorisation (NNMF)</li>
<li>Using neural networks for recommendations</li>
</ol>
<p>I’ll be using the Movielens-100k dataset for illustration. There are 943 users and 1682 movies. In total there are a 100k ratings in the dataset. It should be noted that the max. total number of rating for the &lt;users, movies&gt; would be 943*1682, which means that we have about 7% of the total ratings! All rating are on a scale of 1-5.</p>
<section id="task" class="level3">
<h3 class="anchored" data-anchor-id="task"><strong>Task</strong></h3>
<p>Given this set of ratings, can we recommend the next set of movies to a user? This would translate to: for every user, estimating the ratings for all the movies that (s)he hasn’t watched and maybe recommend the top-k movies by the esimtated ratings!</p>
</section>
<section id="peak-into-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="peak-into-the-dataset">Peak into the dataset</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> pd.read_csv(<span class="st">"/Users/nipun/Downloads/ml-100k/u.data"</span>,sep<span class="op">=</span><span class="st">'</span><span class="ch">\t</span><span class="st">'</span>,names<span class="op">=</span><span class="st">"user_id,item_id,rating,timestamp"</span>.split(<span class="st">","</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>dataset.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>22</td>
      <td>377</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>244</td>
      <td>51</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>166</td>
      <td>346</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>So, each record (row) shows the rating for a user, item (movie) pair. It should be noted that I use item and movie interchangeably in this post.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(dataset.user_id.unique()), <span class="bu">len</span>(dataset.item_id.unique())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(943, 1682)</code></pre>
</div>
</div>
<p>We assign a unique number between (0, #users) to each user and do the same for movies.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dataset.user_id <span class="op">=</span> dataset.user_id.astype(<span class="st">'category'</span>).cat.codes.values</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dataset.item_id <span class="op">=</span> dataset.item_id.astype(<span class="st">'category'</span>).cat.codes.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>dataset.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>195</td>
      <td>241</td>
      <td>3</td>
      <td>881250949</td>
    </tr>
    <tr>
      <th>1</th>
      <td>185</td>
      <td>301</td>
      <td>3</td>
      <td>891717742</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21</td>
      <td>376</td>
      <td>1</td>
      <td>878887116</td>
    </tr>
    <tr>
      <th>3</th>
      <td>243</td>
      <td>50</td>
      <td>2</td>
      <td>880606923</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165</td>
      <td>345</td>
      <td>1</td>
      <td>886397596</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="train-test-split" class="level3">
<h3 class="anchored" data-anchor-id="train-test-split">Train test split</h3>
<p>We’ll now split our dataset of 100k ratings into train (containing 80k ratings) and test (containing 20k ratings). Given the train set, we’d like to accurately estimate the ratings in the test set.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>train, test <span class="op">=</span> train_test_split(dataset, test_size<span class="op">=</span><span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>train.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>90092</th>
      <td>832</td>
      <td>12</td>
      <td>2</td>
      <td>875036139</td>
    </tr>
    <tr>
      <th>50879</th>
      <td>94</td>
      <td>132</td>
      <td>3</td>
      <td>888954341</td>
    </tr>
    <tr>
      <th>67994</th>
      <td>436</td>
      <td>12</td>
      <td>4</td>
      <td>880141129</td>
    </tr>
    <tr>
      <th>49769</th>
      <td>710</td>
      <td>344</td>
      <td>4</td>
      <td>884485683</td>
    </tr>
    <tr>
      <th>11032</th>
      <td>121</td>
      <td>736</td>
      <td>4</td>
      <td>879270874</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>test.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>user_id</th>
      <th>item_id</th>
      <th>rating</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>89284</th>
      <td>907</td>
      <td>493</td>
      <td>3</td>
      <td>879723046</td>
    </tr>
    <tr>
      <th>60499</th>
      <td>550</td>
      <td>25</td>
      <td>4</td>
      <td>892785056</td>
    </tr>
    <tr>
      <th>11090</th>
      <td>373</td>
      <td>222</td>
      <td>5</td>
      <td>880394520</td>
    </tr>
    <tr>
      <th>36096</th>
      <td>199</td>
      <td>140</td>
      <td>4</td>
      <td>884129346</td>
    </tr>
    <tr>
      <th>21633</th>
      <td>71</td>
      <td>317</td>
      <td>5</td>
      <td>880037702</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="matrix-factorisation" class="level3">
<h3 class="anchored" data-anchor-id="matrix-factorisation">Matrix factorisation</h3>
<p>One popular recommender systems approach is called Matrix Factorisation. It works on the principle that we can learn a low-dimensional representation (embedding) of user and movie. For example, for each movie, we can have how much action it has, how long it is, and so on. For each user, we can encode how much they like action, or how much they like long movies, etc. Thus, we can combine the user and the movie embeddings to estimate the ratings on unseen movies. This approach can also be viewed as: given a matrix (A [M X N]) containing users and movies, we want to estimate low dimensional matrices (W [M X k] and H [M X k]), such that: <span class="math inline">\(A \approx W.H^T\)</span></p>
</section>
<section id="matrix-factorisation-in-keras" class="level3">
<h3 class="anchored" data-anchor-id="matrix-factorisation-in-keras">Matrix factorisation in Keras</h3>
<p>We’ll now write some code to solve the recommendation problem by matrix factorisation in Keras. We’re trying to learn two low-dimensional embeddings of users and items.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> SVG</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.optimizers <span class="im">import</span> Adam</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.utils.vis_utils <span class="im">import</span> model_to_dot</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>n_users, n_movies <span class="op">=</span> <span class="bu">len</span>(dataset.user_id.unique()), <span class="bu">len</span>(dataset.item_id.unique())</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>n_latent_factors <span class="op">=</span> <span class="dv">3</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using TensorFlow backend.</code></pre>
</div>
</div>
<p>The key thing is to learn an embedding for movies and users, and then combine them using the dot product! For estimating the rating, for each user, movie pair of interest, we’d take the dot product of the respective user and item embedding. As an example, if we have 2 dimensions in our user and item embedding, which say correspond to [how much user likes action, how much user likes long movies], and the item embedding is [how much action is in the movie, how long is the movie]. Then, we can predict for a user <code>u</code>, and movie <code>m</code> as how much <code>u</code> likes action <span class="math inline">\(\times\)</span> how much action is there in <code>m</code> <span class="math inline">\(+\)</span> how much <code>u</code> likes long movies <span class="math inline">\(\times\)</span> how long is <code>m</code>.</p>
<p>Our model would optimise the emebedding such that we minimise the mean squared error on the ratings from the train set.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>movie_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'Item'</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>movie_embedding <span class="op">=</span> keras.layers.Embedding(n_movies <span class="op">+</span> <span class="dv">1</span>, n_latent_factors, name<span class="op">=</span><span class="st">'Movie-Embedding'</span>)(movie_input)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>movie_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenMovies'</span>)(movie_embedding)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>user_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'User'</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>user_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenUsers'</span>)(keras.layers.Embedding(n_users <span class="op">+</span> <span class="dv">1</span>, n_latent_factors,name<span class="op">=</span><span class="st">'User-Embedding'</span>)(user_input))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>prod <span class="op">=</span> keras.layers.merge([movie_vec, user_vec], mode<span class="op">=</span><span class="st">'dot'</span>,name<span class="op">=</span><span class="st">'DotProduct'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Model([user_input, movie_input], prod)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(<span class="st">'adam'</span>, <span class="st">'mean_squared_error'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s a visualisation of our model for a better understanding.</p>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>SVG(model_to_dot(model,  show_shapes<span class="op">=</span><span class="va">True</span>, show_layer_names<span class="op">=</span><span class="va">True</span>, rankdir<span class="op">=</span><span class="st">'HB'</span>).create(prog<span class="op">=</span><span class="st">'dot'</span>, <span class="bu">format</span><span class="op">=</span><span class="st">'svg'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<p><img src="2017-12-18-recommend-keras_files/figure-html/cell-13-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>We can see that in the <code>Merge</code> layer, we take the dot product of the user and the item embeddings to obtain the rating.</p>
<p>We can also summarise our model as follows:</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Item (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
User (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
Movie-Embedding (Embedding)     (None, 1, 3)         5049        Item[0][0]                       
__________________________________________________________________________________________________
User-Embedding (Embedding)      (None, 1, 3)         2832        User[0][0]                       
__________________________________________________________________________________________________
FlattenMovies (Flatten)         (None, 3)            0           Movie-Embedding[0][0]            
__________________________________________________________________________________________________
FlattenUsers (Flatten)          (None, 3)            0           User-Embedding[0][0]             
__________________________________________________________________________________________________
DotProduct (Merge)              (None, 1)            0           FlattenMovies[0][0]              
                                                                 FlattenUsers[0][0]               
==================================================================================================
Total params: 7,881
Trainable params: 7,881
Non-trainable params: 0
__________________________________________________________________________________________________</code></pre>
</div>
</div>
<p>So, we have 7881 parameters to learn! Let’s train our model now!</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit([train.user_id, train.item_id], train.rating, epochs<span class="op">=</span><span class="dv">100</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="train-error-vs-epoch-number" class="level4">
<h4 class="anchored" data-anchor-id="train-error-vs-epoch-number">Train error v/s epoch number</h4>
<p>Before we test how well our model does in the test setting, we can visualise the train loss with epoch number.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pd.Series(history.history[<span class="st">'loss'</span>]).plot(logy<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Train Error"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>&lt;matplotlib.text.Text at 0x1155a07b8&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2017-12-18-recommend-keras_files/figure-html/cell-16-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="prediction-error" class="level4">
<h4 class="anchored" data-anchor-id="prediction-error">Prediction error</h4>
<p>Let’s now see how our model does! I’ll do a small post-processing step to round off our prediction to the nearest integer. This is usually not done, and thus just a whimsical step, since the training ratings are all integers! There are better ways to encode this intger requirement (one-hot encoding!), but we won’t discuss them in this post.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> np.<span class="bu">round</span>(model.predict([test.user_id, test.item_id]),<span class="dv">0</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> test.rating</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(y_true, y_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>0.6915</code></pre>
</div>
</div>
<p>Not bad! We’re able to get a <span class="math inline">\(MAE\)</span> of 0.69! I’m sure with a bit of parameter/hyper-parameter optimisation, we may be able to improve the results. However, I won’t talk about these optimisations in this post.</p>
</section>
<section id="extracting-the-learnt-embeddings" class="level4">
<h4 class="anchored" data-anchor-id="extracting-the-learnt-embeddings">Extracting the learnt embeddings</h4>
<p>We can extract the learnt movie and item embeddings as follows:</p>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>movie_embedding_learnt <span class="op">=</span> model.get_layer(name<span class="op">=</span><span class="st">'Movie-Embedding'</span>).get_weights()[<span class="dv">0</span>]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(movie_embedding_learnt).describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1683.000000</td>
      <td>1683.000000</td>
      <td>1683.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-0.935420</td>
      <td>0.857862</td>
      <td>0.954169</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.517458</td>
      <td>0.447439</td>
      <td>0.458095</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.524487</td>
      <td>-0.459752</td>
      <td>-0.989537</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.323431</td>
      <td>0.546364</td>
      <td>0.642444</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-0.949188</td>
      <td>0.851243</td>
      <td>0.993619</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-0.550862</td>
      <td>1.159588</td>
      <td>1.283555</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.500618</td>
      <td>2.140607</td>
      <td>2.683658</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>user_embedding_learnt <span class="op">=</span> model.get_layer(name<span class="op">=</span><span class="st">'User-Embedding'</span>).get_weights()[<span class="dv">0</span>]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(user_embedding_learnt).describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>944.000000</td>
      <td>944.000000</td>
      <td>944.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-1.126231</td>
      <td>1.171609</td>
      <td>1.109131</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.517478</td>
      <td>0.409016</td>
      <td>0.548384</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-2.883226</td>
      <td>-0.500010</td>
      <td>-0.415373</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-1.458197</td>
      <td>0.903574</td>
      <td>0.735729</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-1.159480</td>
      <td>1.199517</td>
      <td>1.084089</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-0.836746</td>
      <td>1.456610</td>
      <td>1.468611</td>
    </tr>
    <tr>
      <th>max</th>
      <td>0.899436</td>
      <td>2.605330</td>
      <td>2.826109</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>We can see that both the user and the item embeddings have negative elements. There are some applications which require that the learnt embeddings be non-negative. This approach is also called non-negative matrix factorisation, which we’ll workout now.</p>
</section>
</section>
<section id="non-negative-matrix-factorisation-nnmf-in-keras" class="level3">
<h3 class="anchored" data-anchor-id="non-negative-matrix-factorisation-nnmf-in-keras">Non-negative Matrix factorisation (NNMF) in Keras</h3>
<p>The code for NNMF remains exactly the same as the code for matrix factorisation. The only change is that we add <code>non-negativity</code> constraints on the learnt embeddings. This is done as follows:</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.constraints <span class="im">import</span> non_neg</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>movie_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'Item'</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>movie_embedding <span class="op">=</span> keras.layers.Embedding(n_movies <span class="op">+</span> <span class="dv">1</span>, n_latent_factors, name<span class="op">=</span><span class="st">'NonNegMovie-Embedding'</span>, embeddings_constraint<span class="op">=</span>non_neg())(movie_input)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>movie_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenMovies'</span>)(movie_embedding)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>user_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'User'</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>user_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenUsers'</span>)(keras.layers.Embedding(n_users <span class="op">+</span> <span class="dv">1</span>, n_latent_factors,name<span class="op">=</span><span class="st">'NonNegUser-Embedding'</span>,embeddings_constraint<span class="op">=</span>non_neg())(user_input))</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>prod <span class="op">=</span> keras.layers.merge([movie_vec, user_vec], mode<span class="op">=</span><span class="st">'dot'</span>,name<span class="op">=</span><span class="st">'DotProduct'</span>)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Model([user_input, movie_input], prod)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(<span class="st">'adam'</span>, <span class="st">'mean_squared_error'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now verify if we are indeed able to learn non-negative embeddings. I’ll not compare the performance of NNMF on the test set, in the interest of space.</p>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>history_nonneg <span class="op">=</span> model.fit([train.user_id, train.item_id], train.rating, epochs<span class="op">=</span><span class="dv">10</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>movie_embedding_learnt <span class="op">=</span> model.get_layer(name<span class="op">=</span><span class="st">'NonNegMovie-Embedding'</span>).get_weights()[<span class="dv">0</span>]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(movie_embedding_learnt).describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1683.000000</td>
      <td>1683.000000</td>
      <td>1683.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.838450</td>
      <td>0.840330</td>
      <td>0.838066</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.301618</td>
      <td>0.301529</td>
      <td>0.301040</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-0.000000</td>
      <td>-0.000000</td>
      <td>-0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.657749</td>
      <td>0.663951</td>
      <td>0.656453</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.901495</td>
      <td>0.904192</td>
      <td>0.895934</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.072706</td>
      <td>1.073591</td>
      <td>1.072926</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.365719</td>
      <td>1.379006</td>
      <td>1.373672</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Looks good!</p>
</section>
<section id="neural-networks-for-recommendation" class="level3">
<h3 class="anchored" data-anchor-id="neural-networks-for-recommendation">Neural networks for recommendation</h3>
<p>We’ll now create a simple neural network for recommendation, or for estimating rating! This model is very similar to the earlier matrix factorisation models, but differs in the following ways:</p>
<ol type="1">
<li>Instead of taking a dot product of the user and the item embedding, we concatenate them and use them as features for our neural network. Thus, we are not constrained to the dot product way of combining the embeddings, and can learn complex non-linear relationships.</li>
<li>Due to #1, we can now have a different dimension of user and item embeddings. This can be useful if one dimension is larger than the other.</li>
</ol>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>n_latent_factors_user <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>n_latent_factors_movie <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>movie_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'Item'</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>movie_embedding <span class="op">=</span> keras.layers.Embedding(n_movies <span class="op">+</span> <span class="dv">1</span>, n_latent_factors_movie, name<span class="op">=</span><span class="st">'Movie-Embedding'</span>)(movie_input)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>movie_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenMovies'</span>)(movie_embedding)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>movie_vec <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>)(movie_vec)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>user_input <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>[<span class="dv">1</span>],name<span class="op">=</span><span class="st">'User'</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>user_vec <span class="op">=</span> keras.layers.Flatten(name<span class="op">=</span><span class="st">'FlattenUsers'</span>)(keras.layers.Embedding(n_users <span class="op">+</span> <span class="dv">1</span>, n_latent_factors_user,name<span class="op">=</span><span class="st">'User-Embedding'</span>)(user_input))</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>user_vec <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>)(user_vec)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>concat <span class="op">=</span> keras.layers.merge([movie_vec, user_vec], mode<span class="op">=</span><span class="st">'concat'</span>,name<span class="op">=</span><span class="st">'Concat'</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>concat_dropout <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>)(concat)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>dense <span class="op">=</span> keras.layers.Dense(<span class="dv">200</span>,name<span class="op">=</span><span class="st">'FullyConnected'</span>)(concat)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>dropout_1 <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>,name<span class="op">=</span><span class="st">'Dropout'</span>)(dense)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>dense_2 <span class="op">=</span> keras.layers.Dense(<span class="dv">100</span>,name<span class="op">=</span><span class="st">'FullyConnected-1'</span>)(concat)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>dropout_2 <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>,name<span class="op">=</span><span class="st">'Dropout'</span>)(dense_2)</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>dense_3 <span class="op">=</span> keras.layers.Dense(<span class="dv">50</span>,name<span class="op">=</span><span class="st">'FullyConnected-2'</span>)(dense_2)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>dropout_3 <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>,name<span class="op">=</span><span class="st">'Dropout'</span>)(dense_3)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>dense_4 <span class="op">=</span> keras.layers.Dense(<span class="dv">20</span>,name<span class="op">=</span><span class="st">'FullyConnected-3'</span>, activation<span class="op">=</span><span class="st">'relu'</span>)(dense_3)</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'relu'</span>,name<span class="op">=</span><span class="st">'Activation'</span>)(dense_4)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>adam <span class="op">=</span> Adam(lr<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> keras.Model([user_input, movie_input], result)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span>adam,loss<span class="op">=</span> <span class="st">'mean_absolute_error'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s now see how our model looks like:</p>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>SVG(model_to_dot(model,  show_shapes<span class="op">=</span><span class="va">True</span>, show_layer_names<span class="op">=</span><span class="va">True</span>, rankdir<span class="op">=</span><span class="st">'HB'</span>).create(prog<span class="op">=</span><span class="st">'dot'</span>, <span class="bu">format</span><span class="op">=</span><span class="st">'svg'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<p><img src="2017-12-18-recommend-keras_files/figure-html/cell-25-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>It should be noted that we use a different number of embeddings for user (3) and items (5)! These combine to form a vector of length (5+3 = 8), which is then fed into the neural network. We also add a dropout layer to prevent overfitting!</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Item (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
User (InputLayer)               (None, 1)            0                                            
__________________________________________________________________________________________________
Movie-Embedding (Embedding)     (None, 1, 8)         13464       Item[0][0]                       
__________________________________________________________________________________________________
User-Embedding (Embedding)      (None, 1, 5)         4720        User[0][0]                       
__________________________________________________________________________________________________
FlattenMovies (Flatten)         (None, 8)            0           Movie-Embedding[0][0]            
__________________________________________________________________________________________________
FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8)            0           FlattenMovies[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 5)            0           FlattenUsers[0][0]               
__________________________________________________________________________________________________
Concat (Merge)                  (None, 13)           0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
FullyConnected-1 (Dense)        (None, 100)          1400        Concat[0][0]                     
__________________________________________________________________________________________________
FullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           
__________________________________________________________________________________________________
FullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           
__________________________________________________________________________________________________
Activation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           
==================================================================================================
Total params: 25,675
Trainable params: 25,675
Non-trainable params: 0
__________________________________________________________________________________________________</code></pre>
</div>
</div>
<p>We can see that the number of parameters is more than what we had in the Matrix Factorisation case. Let’s see how this model works. I’ll run it for more epochs given that we have more parameters.</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit([train.user_id, train.item_id], train.rating, epochs<span class="op">=</span><span class="dv">250</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="prediction-performance-of-neural-network-based-recommender-system" class="level4">
<h4 class="anchored" data-anchor-id="prediction-performance-of-neural-network-based-recommender-system">Prediction performance of Neural Network based recommender system</h4>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>y_hat_2 <span class="op">=</span> np.<span class="bu">round</span>(model.predict([test.user_id, test.item_id]),<span class="dv">0</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(y_true, y_hat_2))</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mean_absolute_error(y_true, model.predict([test.user_id, test.item_id])))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6957
0.708807692927</code></pre>
</div>
</div>
<p>Pretty similar to the result we got using matrix factorisation. Maybe, we need to tweak around a lot more with the neural network to get better results?</p>
<p>Thanks for reading. This post has been a good learning experience for me. Hope you enjoyed too!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>